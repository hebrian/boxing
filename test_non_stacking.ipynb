{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Non-stack Version of PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pettingzoo.atari import boxing_v2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from supersuit import pad_observations_v0, pad_action_space_v0, resize_v1, normalize_obs_v0, frame_skip_v0, dtype_v0\n",
    "from pettingzoo.utils import aec_to_parallel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RolloutBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    \"\"\"\n",
    "    Buffer to store rollout data for PPO.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.returns = []\n",
    "        self.advantages = []\n",
    "\n",
    "    def store(self, obs, action, log_prob, reward, done):\n",
    "        if obs.shape[-1] == 3:  # If observation has RGB channels\n",
    "            obs = obs.mean(axis=-1)  # Convert to grayscale\n",
    "        self.observations.append(obs)\n",
    "        self.actions.append(action)\n",
    "        self.log_probs.append(log_prob)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "\n",
    "    def compute_returns_and_advantages(self, policy, gamma, gae_lambda):\n",
    "        \"\"\"\n",
    "        Computes returns and advantages using Generalized Advantage Estimation (GAE).\n",
    "\n",
    "        Parameters:\n",
    "        policy (PPOAgent): The policy network.\n",
    "        gamma (float): Discount factor for rewards.\n",
    "        gae_lambda (float): Lambda parameter for GAE.\n",
    "        \"\"\"\n",
    "        values = [\n",
    "            policy.forward_value(\n",
    "                torch.tensor(\n",
    "                    obs[np.newaxis, np.newaxis, :, :],  # Add batch and channel dimensions (1, 1, H, W)\n",
    "                    dtype=torch.float32\n",
    "                ) / 255.0  # Normalize\n",
    "            ).item()\n",
    "            for obs in self.observations\n",
    "        ]\n",
    "\n",
    "\n",
    "        next_value = 0 if self.dones[-1] else values[-1]\n",
    "\n",
    "        # GAE computation\n",
    "        returns = []\n",
    "        advantages = []\n",
    "        gae = 0\n",
    "        for step in reversed(range(len(self.rewards))):\n",
    "            delta = self.rewards[step] + gamma * next_value * (1 - self.dones[step]) - values[step]\n",
    "            gae = delta + gamma * gae_lambda * (1 - self.dones[step]) * gae\n",
    "            advantages.insert(0, gae)\n",
    "            next_value = values[step]\n",
    "            returns.insert(0, gae + values[step])\n",
    "\n",
    "        self.returns = returns\n",
    "        self.advantages = advantages\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Clears the buffer.\n",
    "        \"\"\"\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.returns = []\n",
    "        self.advantages = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO Agent(Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(nn.Module):\n",
    "    def __init__(self, obs_shape, action_space):\n",
    "        super(PPOAgent, self).__init__()\n",
    "        \n",
    "        # Convolutional layers adapted for single-channel input\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(obs_shape[0], 32, kernel_size=8, stride=4),  # obs_shape[0] is the channel size\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Dynamically calculate the feature map size\n",
    "        feature_map_size = self.calculate_feature_map_size(obs_shape)\n",
    "        \n",
    "        # Policy network\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_map_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_space.n),\n",
    "        )\n",
    "        \n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_map_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward_policy(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the policy network.\n",
    "        Converts the observation to a probability distribution over actions.\n",
    "        \"\"\"\n",
    "        x = self.conv_layers(x)\n",
    "        return torch.softmax(self.policy_net(x), dim=-1)\n",
    "\n",
    "    def forward_value(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the value network.\n",
    "        Converts the observation to an estimated value.\n",
    "        \"\"\"\n",
    "        x = self.conv_layers(x)\n",
    "        return self.value_net(x)\n",
    "\n",
    "    def calculate_feature_map_size(self, input_shape):\n",
    "        \"\"\"\n",
    "        Calculates the feature map size after the convolutional layers.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)  # Batch size of 1\n",
    "            output = self.conv_layers(dummy_input)\n",
    "            print(\"Shape after conv layers:\", output.size())  # Debugging output shape\n",
    "        return int(np.prod(output.size()[1:]))  # Flatten the output shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    \"\"\"\n",
    "    Proximal Policy Optimization (PPO) implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_shape, action_space, lr=3e-3, gamma=0.8, epsilon=0.2, gae_lambda=0.95):\n",
    "        self.policy = PPOAgent(obs_shape, action_space)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "    def update(self, buffer):\n",
    "        \"\"\"\n",
    "        Updates the policy and value networks using PPO loss.\n",
    "\n",
    "        Parameters:\n",
    "        buffer (RolloutBuffer): The buffer containing rollout data.\n",
    "        \"\"\"\n",
    "        obs_array = np.array(buffer.observations, dtype=np.float32)  # Combine into a single numpy array\n",
    "        obs_array = np.array(buffer.observations, dtype=np.float32)  # Combine into a single numpy array\n",
    "        if len(obs_array.shape) == 3:  # Handle grayscale observations (Batch, H, W)\n",
    "            obs = torch.tensor(obs_array, dtype=torch.float32).unsqueeze(1) / 255.0  # Add channel dim (Batch, 1, H, W)\n",
    "        else:  # If stacking was used and there are 4D observations\n",
    "            obs = torch.tensor(obs_array, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # (Batch, Channels, H, W)\n",
    "        # print(f\"Observation Shape in Update: {obs.shape}\")  # Debug shape\n",
    "\n",
    "        actions = torch.tensor(buffer.actions, dtype=torch.int64)\n",
    "        old_log_probs = torch.tensor(buffer.log_probs, dtype=torch.float32)\n",
    "        returns = torch.tensor(buffer.returns, dtype=torch.float32)\n",
    "        advantages = torch.tensor(buffer.advantages, dtype=torch.float32)\n",
    "\n",
    "        for _ in range(10):  # Number of PPO epochs\n",
    "            # Get new log probabilities and values\n",
    "            new_probs = self.policy.forward_policy(obs).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "            new_log_probs = torch.log(new_probs + 1e-8)\n",
    "            values = self.policy.forward_value(obs).squeeze(-1)\n",
    "            # print(f\"Values Shape in Update: {values.shape}\")\n",
    "\n",
    "            # Compute the ratio\n",
    "            ratio = torch.exp(new_log_probs - old_log_probs)\n",
    "\n",
    "            # Compute the clipped surrogate objective\n",
    "            surr1 = ratio * advantages\n",
    "            surr2 = torch.clamp(ratio, 1 - self.epsilon, 1 + self.epsilon) * advantages\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            value_loss = nn.MSELoss()(values, returns)\n",
    "\n",
    "            # Total loss\n",
    "            loss = policy_loss + 0.5 * value_loss\n",
    "\n",
    "            # Gradient update\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Episode 1: Total Reward = 0\n",
      "Episode 1: Updating PPO model...\n",
      "Episode 1/50 completed.\n",
      "Episode 2: Total Reward = 0\n",
      "Episode 2: Updating PPO model...\n",
      "Episode 2/50 completed.\n",
      "Episode 3: Total Reward = 0\n",
      "Episode 3: Updating PPO model...\n",
      "Episode 3/50 completed.\n",
      "Episode 4: Total Reward = 0\n",
      "Episode 4: Updating PPO model...\n",
      "Episode 4/50 completed.\n",
      "Episode 5: Total Reward = 0\n",
      "Episode 5: Updating PPO model...\n",
      "Episode 5/50 completed.\n",
      "Episode 6: Total Reward = 0\n",
      "Episode 6: Updating PPO model...\n",
      "Episode 6/50 completed.\n",
      "Episode 7: Total Reward = 0\n",
      "Episode 7: Updating PPO model...\n",
      "Episode 7/50 completed.\n",
      "Episode 8: Total Reward = 0\n",
      "Episode 8: Updating PPO model...\n",
      "Episode 8/50 completed.\n",
      "Episode 9: Total Reward = 0\n",
      "Episode 9: Updating PPO model...\n",
      "Episode 9/50 completed.\n",
      "Episode 10: Total Reward = 0\n",
      "Episode 10: Updating PPO model...\n",
      "Episode 10/50 completed.\n",
      "Episode 11: Total Reward = 0\n",
      "Episode 11: Updating PPO model...\n",
      "Episode 11/50 completed.\n",
      "Episode 12: Total Reward = 0\n",
      "Episode 12: Updating PPO model...\n",
      "Episode 12/50 completed.\n",
      "Episode 13: Total Reward = 0\n",
      "Episode 13: Updating PPO model...\n",
      "Episode 13/50 completed.\n",
      "Episode 14: Total Reward = 0\n",
      "Episode 14: Updating PPO model...\n",
      "Episode 14/50 completed.\n",
      "Episode 15: Total Reward = 0\n",
      "Episode 15: Updating PPO model...\n",
      "Episode 15/50 completed.\n",
      "Episode 16: Total Reward = 0\n",
      "Episode 16: Updating PPO model...\n",
      "Episode 16/50 completed.\n",
      "Episode 17: Total Reward = 0\n",
      "Episode 17: Updating PPO model...\n",
      "Episode 17/50 completed.\n",
      "Episode 18: Total Reward = 0\n",
      "Episode 18: Updating PPO model...\n",
      "Episode 18/50 completed.\n",
      "Episode 19: Total Reward = 0\n",
      "Episode 19: Updating PPO model...\n",
      "Episode 19/50 completed.\n",
      "Episode 20: Total Reward = 0\n",
      "Episode 20: Updating PPO model...\n",
      "Episode 20/50 completed.\n",
      "Episode 21: Total Reward = 0\n",
      "Episode 21: Updating PPO model...\n",
      "Episode 21/50 completed.\n",
      "Episode 22: Total Reward = 0\n",
      "Episode 22: Updating PPO model...\n",
      "Episode 22/50 completed.\n",
      "Episode 23: Total Reward = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Compute Returns and Advantages\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Total Reward = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m \u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_returns_and_advantages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgae_lambda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Update PPO\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Updating PPO model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m, in \u001b[0;36mRolloutBuffer.compute_returns_and_advantages\u001b[0;34m(self, policy, gamma, gae_lambda)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_returns_and_advantages\u001b[39m(\u001b[38;5;28mself\u001b[39m, policy, gamma, gae_lambda):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Computes returns and advantages using Generalized Advantage Estimation (GAE).\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    gae_lambda (float): Lambda parameter for GAE.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m         policy\u001b[38;5;241m.\u001b[39mforward_value(\n\u001b[1;32m     35\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m     36\u001b[0m                 obs[np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis, :, :],  \u001b[38;5;66;03m# Add batch and channel dimensions (1, 1, H, W)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m                 dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m     38\u001b[0m             ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         )\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations\n\u001b[1;32m     41\u001b[0m     ]\n\u001b[1;32m     44\u001b[0m     next_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdones[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# GAE computation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_returns_and_advantages\u001b[39m(\u001b[38;5;28mself\u001b[39m, policy, gamma, gae_lambda):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Computes returns and advantages using Generalized Advantage Estimation (GAE).\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    gae_lambda (float): Lambda parameter for GAE.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     values \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 34\u001b[0m         \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add batch and channel dimensions (1, 1, H, W)\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Normalize\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations\n\u001b[1;32m     41\u001b[0m     ]\n\u001b[1;32m     44\u001b[0m     next_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdones[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# GAE computation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 46\u001b[0m, in \u001b[0;36mPPOAgent.forward_value\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    Forward pass of the value network.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    Converts the observation to an estimated value.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(x)\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DS153/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Set up the environment\n",
    "env = boxing_v2.env(render_mode=\"rgb_array\")\n",
    "env.reset(seed=42)\n",
    "env = pad_observations_v0(env)\n",
    "env = pad_action_space_v0(env)\n",
    "env = resize_v1(env, 84, 84)  # Resize frames to 84x84\n",
    "env = dtype_v0(env, dtype=\"float32\")  # Convert observations to float32\n",
    "env = normalize_obs_v0(env, env_min=0, env_max=1)  # Normalize pixel values\n",
    "parallel_env = aec_to_parallel(env)  # Convert to parallel format\n",
    "\n",
    "# Step 2: Initialize PPO and RolloutBuffer\n",
    "obs_shape = (1, 84, 84)  # Single frame (no stacking)\n",
    "action_space = env.action_space(\"first_0\")  # Example action space for an agent\n",
    "ppo = PPO(obs_shape, action_space)\n",
    "buffer = RolloutBuffer()\n",
    "\n",
    "# Step 3: Training Loop\n",
    "num_episodes = 50\n",
    "max_steps_per_episode = 1000  # Maximum steps to prevent infinite loops\n",
    "# Initialize reward tracking\n",
    "cumulative_rewards = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    # Reset the environment\n",
    "    observations = parallel_env.reset()\n",
    "\n",
    "    # Extract nested observations (first element of the tuple)\n",
    "    if isinstance(observations, tuple) and len(observations) > 0:\n",
    "        agent_observations = observations[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "    # Initialize done flags for each agent\n",
    "    done = {agent: False for agent in agent_observations.keys()}\n",
    "    step = 0\n",
    "    episode_reward = 0  # Track total reward for the episode\n",
    "\n",
    "    while not all(done.values()) and step < max_steps_per_episode:\n",
    "        actions = {}\n",
    "        log_probs = {}\n",
    "\n",
    "        # Process observations for each agent\n",
    "        for agent, obs in agent_observations.items():\n",
    "            # Convert observations to grayscale if needed\n",
    "            if obs.shape[-1] == 3:  # If RGB format\n",
    "                obs = obs.mean(axis=-1)  # Convert to grayscale by averaging RGB channels\n",
    "\n",
    "            # Prepare tensor\n",
    "            obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "\n",
    "            # Get action probabilities\n",
    "            action_probs = ppo.policy.forward_policy(obs_tensor)\n",
    "            action = torch.multinomial(action_probs, 1).item()  # Sample action\n",
    "            log_probs[agent] = torch.log(action_probs.squeeze(0)[action])  # Log probability\n",
    "            actions[agent] = action  # Store action\n",
    "\n",
    "        # Step the environment\n",
    "        step_output = parallel_env.step(actions)\n",
    "\n",
    "        if len(step_output) == 5:  # Handle truncations\n",
    "            next_observations, rewards, dones, truncations, infos = step_output\n",
    "            dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "            # print(f\"observations: {next_observations}\")\n",
    "        else:\n",
    "            next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "        # Extract nested observations for next step\n",
    "        if isinstance(next_observations, dict):\n",
    "            agent_observations = next_observations  # Observations are already in dictionary format\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected observation structure after step: {type(next_observations)}\")\n",
    "\n",
    "        # Accumulate rewards\n",
    "        episode_reward += sum(rewards.values())  # Sum rewards from all agents\n",
    "\n",
    "        # Store data in the buffer for each agent\n",
    "        for agent, obs in agent_observations.items():\n",
    "            buffer.store(obs, actions[agent], log_probs[agent].item(), rewards[agent], dones[agent])\n",
    "\n",
    "        # Update done flags\n",
    "        done = dones\n",
    "        step += 1\n",
    "\n",
    "    # Append episode reward\n",
    "    cumulative_rewards.append(episode_reward)\n",
    "\n",
    "    # Compute Returns and Advantages\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {episode_reward}\")\n",
    "    buffer.compute_returns_and_advantages(ppo.policy, ppo.gamma, ppo.gae_lambda)\n",
    "\n",
    "    # Update PPO\n",
    "    print(f\"Episode {episode + 1}: Updating PPO model...\")\n",
    "    ppo.update(buffer)\n",
    "\n",
    "    # Clear buffer for the next episode\n",
    "    buffer.clear()\n",
    "\n",
    "    # Log progress\n",
    "    print(f\"Episode {episode + 1}/{num_episodes} completed.\")\n",
    "\n",
    "# Plot cumulative rewards\n",
    "plt.plot(cumulative_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Training Progress')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Actions: {'first_0': 9, 'second_0': 4}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "print(f\"Sampled Actions: {actions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: first_0, Sampled Action: 7\n",
      "Agent: second_0, Sampled Action: 4\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    action = env.action_space(agent).sample()\n",
    "    print(f\"Agent: {agent}, Sampled Action: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_accumulate_rewards', '_check_wrapper_params', '_clear_rewards', '_deads_step_first', '_has_rendered', '_has_reset', '_has_updated', '_is_protocol', '_modify_action', '_modify_observation', '_modify_spaces', '_update_step', '_was_dead_step', 'action_space', 'agent_iter', 'change_obs_space_fn', 'change_observation_fn', 'close', 'env', 'last', 'max_num_agents', 'num_agents', 'observation_space', 'observe', 'render', 'reset', 'state', 'step', 'unwrapped']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dir(env))  # Check available attributes and methods\n",
    "print(env.reset.__doc__)  # Print the docstring of the reset method if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards at 5999: defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9IAAAH6CAYAAADr83SsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwQklEQVR4nO3deZzVVf0/8PfIjDPAoGyjqCgoKGRCqKBiKi4JmpqZuWKJRotLpmluP4gMvupXy7TFpVRMIcM9w40S8WGZihluiH4Vl2+5gOIGiIqc3x9+GR3vZ/QeZgYGeD4fD/7gfd/33DOfQc993fOZMxUppRQAAABAWdZY0RMAAACAlYkgDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIIMgTatz//33x3777RcbbbRRVFdXx7rrrhuDBw+OE088sUHfhRdeGFdcccWKmeT/ufLKK+Pggw+OPn36xBprrBE9e/bMHuN///d/49hjj41evXpFTU1NdOrUKXbeeeeYOHFipJQa9E6bNi0qKiriuuuua6avoPW59dZb4yc/+UnhYz179owRI0Ys1/kArE5W1TV4/vz5cfzxx8f6668fNTU1MWDAgPjjH/9Y2PvQQw/Fl770paitrY2OHTvG1772tZg9e3bZ81qwYEGcffbZseWWW0ZtbW20b98+BgwYEGeeeWYsWLCgpL+ioiKOPfbYssdf2cycOTN+8pOfxHPPPVfy2IgRI5bpvRO0BoI0rcott9wS22+/fbz11ltxzjnnxJQpU+KCCy6IL37xizFp0qQGva1hEb/qqqvi8ccfj2222SZ69eqV/fy///3v0b9///jTn/4UP/jBD+L222+PK664IjbYYIM47LDD4pBDDoklS5a0wMxbr1tvvTXOOOOMwsduvPHGGD169HKeEcDqYVVeg7/2ta/F73//+xgzZkzcdtttMWjQoDjkkEPiD3/4Q4O+WbNmxc477xzvvfdeXHPNNXH55ZfHU089FTvuuGPMnTv3M+f0yiuvxHbbbRc//elPY9iwYXHjjTfGTTfdFHvuuWeMGzcutttuu3jllVea9HWvbGbOnBlnnHFGYZAePXp03Hjjjct/UtAcErQiO+20U+rVq1d6//33Sx774IMPGvz985//fBoyZMhymlmxj89pr732Sj169Cj7ua+//npaZ511Uo8ePdLLL79c8vjZZ5+dIiKdddZZ9bW77rorRUS69tprmzTv5rBgwYIWGfeYY45J/tcEsPytqmvwLbfckiIi/eEPf2hQ33333dP666+fFi9eXF874IADUteuXdObb75ZX3vuuedSVVVVOvnkkz9zTkOHDk2VlZXpnnvuKXnsnnvuSZWVlWnYsGEN6hGRjjnmmM8cu6UtXLgwLVmypNnHvfbaa1NEpLvuuqvZx4YVyY40rcprr70WXbt2jcrKypLH1ljjo3+uPXv2jMcffzzuvvvuqKioiIqKiga3Br311ltx0kknxcYbbxxrrrlmbLDBBnH88ceX3FK19HaqSy65JDbbbLOorq6OzTffvNHbvT5tTrkuvfTSmDNnTpx99tmx7rrrljx+8sknR9++fePcc8+N999/v8FjixYtih/+8IfRrVu3aNu2bQwZMiT+9a9/NeiZPXt2HHzwwbH++uvX35632267xYwZMxr0TZo0KQYPHhzt27eP2traGDZsWMlYI0aMiNra2nj00Udj6NCh0aFDh9htt93i+OOPj/bt28dbb71VMv+DDjoo1l133fq5T5o0KYYOHRrrrbdetG3bNj73uc/Fqaee2uB7MmLEiPjNb34TEVH/fa2oqKj/FLvo1u4XXnghDjvssFhnnXWiuro6Pve5z8XPf/7zBjv5zz33XFRUVMTPfvazOO+882LjjTeO2traGDx4cNx3330F3x2A1c+qugbfeOONUVtbGwcccECD+hFHHBEvvvhi3H///RERsXjx4pg8eXLsv//+sdZaa9X39ejRI3bZZZfP3Dl98MEHY8qUKfGtb30rdthhh5LHd9hhhzjyyCPjjjvuiH/+858lj3/WdVi4cGH9da2pqYnOnTvHwIED4+qrry6Zx1e+8pXo3Llz1NTUxJZbbhnXXHNNg54rrrgiKioqYsqUKXHkkUdGXV1dtGvXLiZNmhQVFRVx5513lszvoosuioqKinjkkUfqX+fggw+Onj17Rtu2baNnz55xyCGHxPPPP9/gdZZe91122aX+38vSuxmKbu1etGhRnHbaaQ3+/RxzzDHxxhtvNOjr2bNn7L333nH77bfHVlttFW3bto2+ffvG5ZdfXjJ3aBErOsnDx40cOTJFRPr+97+f7rvvvvTee+8V9j300ENpk002SVtuuWX6xz/+kf7xj3+khx56KKX04U7pgAEDUteuXdN5552X/vrXv6YLLrggrb322mnXXXdt8GlrRKQNN9wwbb755unqq69ON998c9pjjz2Wadc3d0d66NChqU2bNmn+/PmN9px88skpItI//vGPlNJHO9Ibbrhh2nfffdOf//znNGHChNS7d++01lprpWeeeab+uX369Em9e/dOV111Vbr77rvT9ddfn0488cQGnwj/13/9V6qoqEhHHnlkmjx5crrhhhvS4MGDU/v27dPjjz9e33f44Yenqqqq1LNnz3TWWWelO++8M91xxx3p4YcfThGRfve73zWY9+uvv56qq6vTD3/4w/ra2LFj0y9+8Yt0yy23pGnTpqWLL744bbzxxmmXXXap73n66afT17/+9fqveemfRYsWpZRS6tGjRzr88MPr++fMmZM22GCDVFdXly6++OJ0++23p2OPPTZFRDrqqKPq+5599tkUEalnz55pjz32SDfddFO66aabUr9+/VKnTp3SG2+8UeZ3DWDVtaquwdttt10aNGhQSf2xxx5LEZEuueSSlFJKs2bNShGRfvOb35T0nnTSSamioiK98847jc7hzDPPTBGRbrvttkZ7br311pK7zcq9Dt/97ndTu3bt0nnnnZfuuuuuNHny5HT22WenX/3qV/U9U6dOTWuuuWbacccd06RJk9Ltt9+eRowYkSIijR8/vr5v/PjxKSLSBhtskL7zne+k2267LV133XVp0aJFaZ111knDhw8vmfs222yTttpqq/q/X3vttenHP/5xuvHGG9Pdd9+d/vjHP6YhQ4akurq6NHfu3JTSh+v00uvym9/8pv7fy5w5c1JKH76/+Pj3bcmSJWnYsGGpsrIyjR49Ok2ZMiX97Gc/S+3bt09bbrll/fuBlD58T9C9e/e0+eabpyuvvDLdcccd6YADDkgRke6+++5GvwfQXARpWpVXX3017bDDDikiUkSkqqqqtP3226ezzjorvf322w16G7ut7KyzzkprrLFGmj59eoP6ddddlyIi3XrrrfW1iEht27ZtcGv14sWLU9++fVPv3r2z5p4bpPv27Zu6dev2qT0XXXRRiog0adKklNJHQXqrrbZq8GZk6W1nI0eOTCl9eB0jIp1//vmNjv3CCy+kysrK9P3vf79B/e23307dunVLBx54YH3t8MMPTxGRLr/88pJxttpqq7T99ts3qF144YUpItKjjz5a+NpLlixJ77//frr77rtTRKSHH364/rFPu7X7k0H61FNPTRGR7r///gZ9Rx11VKqoqEhPPvlkSumjIN2vX78Gt/A98MADKSLS1VdfXfh6AKuTVXUN3nTTTUtup04ppRdffDFFRDrzzDNTSin9/e9/b3RNWBoGX3zxxUbn8L3vfS9FRJo1a1ajPU888UTJh73lXoctttgiffWrX2107JQ+fG+x5ZZbltyev/fee6f11luv/nb4pUH6m9/8ZskYP/zhD1Pbtm0bfMg8c+bMFBENQvsnLV68OM2fPz+1b98+XXDBBfX1T7u1+5NB+vbbb08Rkc4555wGfZMmTUoRkX7729/W13r06JFqamrS888/X1975513UufOndN3v/vdRucJzcWt3bQqXbp0iXvuuSemT58eZ599duy7777x1FNPxWmnnRb9+vWLV1999TPHmDx5cmyxxRYxYMCAWLx4cf2fYcOGRUVFRUybNq1B/2677dbg1uo2bdrEQQcdFE8//XT8+9//bu4vMUv6v1O7KyoqGtQPPfTQBrUePXrE9ttvH3fddVdERHTu3Dl69eoV5557bpx33nnxr3/9q+TQsjvuuCMWL14c3/zmNxtcp5qamhgyZEjJdYqI2H///UtqRxxxRNx7773x5JNP1tfGjx8fgwYNii222KK+Nnv27Dj00EOjW7du0aZNm6iqqoohQ4ZERMQTTzyReWU+NHXq1Nh8881jm222aVAfMWJEpJRi6tSpDep77bVXtGnTpv7v/fv3j4hocBsawOpqVV6DP7mOftpjOb25GlvXy7kO22yzTdx2221x6qmnxrRp0+Kdd95pMMbTTz8ds2bNiuHDh0dENLj+X/7yl+Oll15qsFZHFK/rRx55ZLzzzjsNDpgbP358VFdXx6GHHlpfmz9/fpxyyinRu3fvqKysjMrKyqitrY0FCxY0aV2PiJIf4zrggAOiffv2JbecDxgwIDbaaKP6v9fU1MRmm21mXWe5EKRplQYOHBinnHJKXHvttfHiiy/GCSecEM8991ycc845n/ncV155JR555JGoqqpq8KdDhw6RUip5I9CtW7eSMZbWXnvtteb5ggpstNFGMXfu3MJfhbHU0p8N3nDDDQvn98na0vku/fmmYcOGxTnnnBNbbbVV1NXVxXHHHRdvv/12RET9qaGDBg0quVaTJk0quU7t2rVr8DNjSw0fPjyqq6vrf95p5syZMX369DjiiCPqe+bPnx877rhj3H///TFu3LiYNm1aTJ8+PW644YaIiJI3A+V67bXXYr311iupr7/++vWPf1yXLl0a/L26urpJrw+wKlrV1uAuXboUjjVv3ryI+PDD56V9jb3uvHnzoqKiIjp27Njo6ywNdM8++2yjPbnr+sfn88tf/jJOOeWUuOmmm2KXXXaJzp07x1e/+tX4n//5n4j4aF0/6aSTSq7/0UcfHRFRcv2L1tDPf/7zMWjQoBg/fnxERHzwwQcxYcKE2HfffeuvVcSHH+r/+te/jpEjR8Ydd9wRDzzwQEyfPj3q6uqatK5XVlZGXV1dg3pFRUWD9zlLfXJdj/hwbbeuszyUniYBrUxVVVWMGTMmfvGLX8Rjjz32mf1du3aNtm3bNnrYRNeuXRv8/eWXXy7pWVor+h90c9l9991jypQp8ec//zkOPvjgksdTSnHzzTdH586dY+utty6c3ydrH59vjx494rLLLouIiKeeeiquueaa+MlPfhLvvfdeXHzxxfXX4brrrosePXp85nwb+xS+U6dOse+++8aVV14Z48aNi/Hjx0dNTU0ccsgh9T1Tp06NF198MaZNm1a/Cx0RJQeH5OrSpUu89NJLJfUXX3wxIkq/1wDkWRXW4H79+sXVV18dixcvbnCQ2qOPPhoRUX/3VK9evaJt27b19Y979NFHo3fv3lFTU9Po6+y+++5x+umnx0033RR77LFHYc9NN91U3/tx5VyH9u3bxxlnnBFnnHFGvPLKK/W70/vss0/MmjWr/tqedtpp8bWvfa3w9fv06dPg742t7UcccUQcffTR8cQTT8Ts2bPjpZdeavAB+ZtvvhmTJ0+OMWPGxKmnnlpff/fdd+s/oFgWXbp0icWLF8fcuXMbhOmUUrz88ssxaNCgZR4bmpsdaVqVolAU8dGtv0t3GiMa/8Rx7733jmeeeSa6dOkSAwcOLPnzydMh77zzzga/0/GDDz6ISZMmRa9evaJ79+7N8FUVGzlyZKyzzjpx2mmnxZw5c0oeP+ecc2LWrFlx8sknR1VVVYPHrr766vrbwyI+vDX53nvvjZ133rnwtTbbbLMYNWpU9OvXLx566KGIiBg2bFhUVlbGM888U3idBg4cWPbXsvTk01tvvTUmTJgQ++23X4NP7Zcu1Et3gJe65JJLSsbK2SXebbfdYubMmfVf01JXXnllVFRUxC677FL21wCwultV1+D99tsv5s+fH9dff32D+u9///tYf/31Y9ttt42IiMrKythnn33ihhtuqL97K+LD3w5x1113NRpOlxo4cGAMHTo0Lrvssvj73/9e8vjf/va3uPzyy2OPPfYo+YA89zqsu+66MWLEiDjkkEPiySefjIULF0afPn1i0003jYcffrjRdb1Dhw6ffcEi4pBDDomampq44oor4oorrogNNtgghg4dWv94RUVFpJRK1vVLL700Pvjggwa13HU9ImLChAkN6tdff30sWLCg/nFoDexI06oMGzYsunfvHvvss0/07ds3lixZEjNmzIif//znUVtbGz/4wQ/qe/v16xd//OMfY9KkSbHJJptETU1N9OvXL44//vi4/vrrY6eddooTTjgh+vfvH0uWLIkXXnghpkyZEieeeGL9ohnx4afju+66a4wePTrat28fF154YcyaNausX78xc+bMmDlzZkR8+MnxwoUL47rrrouIiM033zw233zzRp/bsWPHuOGGG2LvvfeOrbfeOn70ox/FF77whXjrrbdi0qRJMXHixDjooIPiRz/6Uclz58yZE/vtt198+9vfjjfffDPGjBkTNTU1cdppp0VExCOPPBLHHntsHHDAAbHpppvGmmuuGVOnTo1HHnmk/pPjnj17xk9/+tP4f//v/8Xs2bNjjz32iE6dOsUrr7wSDzzwQP0n3+UYOnRodO/ePY4++uh4+eWXG3xqHRGx/fbbR6dOneJ73/tejBkzJqqqqmLixInx8MMPl4zVr1+/iIj47//+79hzzz2jTZs20b9//1hzzTVLek844YS48sorY6+99oqf/vSn0aNHj7jlllviwgsvjKOOOio222yzsuYPwKq7Bu+5556x++67x1FHHRVvvfVW9O7dO66++uq4/fbbY8KECQ3OzjjjjDNi0KBBsffee8epp54aixYtih//+MfRtWvXOPHEEz9zTldeeWV86UtfiqFDh8Zxxx1XH/ymTp0aF1xwQfTt27f+R6E+rpzrsO2228bee+8d/fv3j06dOsUTTzwRV111VQwePDjatWsXER9+QL3nnnvGsGHDYsSIEbHBBhvEvHnz4oknnoiHHnoorr322s/8GiI+fI+y3377xRVXXBFvvPFGnHTSSQ1+3dhaa60VO+20U5x77rnRtWvX6NmzZ9x9991x2WWXldz+vnTH/7e//W106NAhampqYuONNy6842D33XePYcOGxSmnnBJvvfVWfPGLX4xHHnkkxowZE1tuuWV84xvfKGv+sFyssGPOoMCkSZPSoYcemjbddNNUW1ubqqqq0kYbbZS+8Y1vpJkzZzbofe6559LQoUNThw4dUkQ0OPVx/vz5adSoUalPnz5pzTXXTGuvvXbq169fOuGEExqcihkR6ZhjjkkXXnhh6tWrV6qqqkp9+/ZNEydOLGu+Y8aMqT/d9JN/xowZU9YYL7zwQjrmmGPSJptsUj/XnXbaKU2YMKHBydwpfXRq91VXXZWOO+64VFdXl6qrq9OOO+6YHnzwwfq+V155JY0YMSL17ds3tW/fPtXW1qb+/funX/ziFw1OrU4ppZtuuintsssuaa211krV1dWpR48e6etf/3r661//Wt9z+OGHp/bt23/q13H66afX/wqPpaeCfty9996bBg8enNq1a5fq6urSyJEj00MPPVTyKznefffdNHLkyFRXV5cqKipSRKRnn302pVR6andKKT3//PPp0EMPTV26dElVVVWpT58+6dxzz20wh6Wndp977rkl88r5XgGsylblNfjtt99Oxx13XOrWrVtac801U//+/Rv9jQ0PPvhg2m233VK7du3SWmutlb761a+mp59+uryL+H9f/5lnnpkGDBiQ2rVrl9q1a5f69++fxo0bV/grL8u9DqeeemoaOHBg6tSpU6qurk6bbLJJOuGEE9Krr77aoO/hhx9OBx54YFpnnXVSVVVV6tatW9p1113TxRdfXN+z9NTuT56u/nFTpkypv55PPfVUyeP//ve/0/777586deqUOnTokPbYY4/02GOPFa7V559/ftp4441TmzZtGqz7nzy1O6UPT94+5ZRTUo8ePVJVVVVab7310lFHHZVef/31Bn09evRIe+21V8m8hgwZUniiPDS3ipQ+dn8orGYqKirimGOOiV//+tcreioAsFqxBgMrMz8jDQAAABkEaQAAAMjg1m4AAADIYEcaAAAAMgjSAAAAkEGQBgAAgAyCNAAAAGSoLLexoqKiRSYwduzYFhkXAFqbUaNGLZfXsWYDQNN81pptRxoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyVK7oCbDy+sIXvlBY32KLLQrrd9xxR0ntiCOOKOw999xzl31i0ELGjx9fWG/sv4V58+aV1N55553C3n322WfZJwbwGXLX7IkTJ7bkdGCFueWWWwrr9913X0lt7NixLT0dVmJ2pAEAACCDIA0AAAAZBGkAAADIIEgDAABABkEaAAAAMji1GwBgFffss88W1hcsWFBY33rrrUtqPXv2LOy9/vrrl3le0FIa+00blZXlx5/777+/sL7tttsu05xYtdiRBgAAgAyCNAAAAGQQpAEAACCDIA0AAAAZHDbGMnv44YcL6wMHDiys77vvviW1c889t1nnBC3piCOOKKxfeOGFZY9x9NFHN9d0AMrWrVu3wvqOO+5Y9hiXXXZZc00HWlxja3ZjitZyh4rxaexIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcGo3zc6pnqxunMQNtHZPPfVUVh1WN9ZyctmRBgAAgAyCNAAAAGQQpAEAACCDIA0AAAAZHDbGau/dd98trC9YsKCw3rlz55acTlkWLlxYUlu0aFHWGFVVVSW1Dh06FPbOmzev7HHXXnvtklqbNm3KnxgANCJ3za6sLH2ru9ZaazXrnJZFY+tqdXV1Yb19+/ZNHruINRuWnR1pAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMTu1mtfef//ynsD516tTC+siRI5v0epMmTSqs77zzziW1ddddt7D30UcfLfv1tt1227J758+fX1i/8cYbS2rf+ta3CnsvvfTSklpTrxkARERcddVVhfXG1pmmrknNsWa/9tprJbXHHnussPeDDz4orO+6664lNWs2rFh2pAEAACCDIA0AAAAZBGkAAADIIEgDAABABoeNsdrbZJNNCuuNHTbWGnzhC18oqdXU1BT2zp49u7D++OOPl9T22muvwt7GDikBAD5dly5dSmqdO3cu7J07d27Z47Zr166wbs2G5cOONAAAAGQQpAEAACCDIA0AAAAZBGkAAADIIEgDAABAhoqUUiqrsaKiRSYwduzYFhkXyvX00083eYzevXs3w0zK9+qrr5bU3njjjawxcuacc4023HDDklp1dXXZz4dV2ahRo5bL61izWVW9+eabhfXGTrsuWn+K1qmW1BxrdtFv5ujevXthrzUbmsdnrdl2pAEAACCDIA0AAAAZBGkAAADIIEgDAABABkEaAAAAMlSu6AmsjDp37lxSa9euXZPHfffddwvrjZ1ESfNY3iduN4euXbuWVWsuK+M1onF1dXWF9eY4qXXhwoUltXnz5jV5XFhW1uxVy9prr51Vbw2s2TSFNbv1siMNAAAAGQRpAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyFC5oifAR6qrqwvr3bt3X84zAQA+jTUbYPVmRxoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQoXJFT2BlNG/evLJqERG1tbUltY4dOxb2vvvuu4X1uXPnlj85gM9QV1dXWK+uri6sv/HGGyW1+fPnN+eUoMVYs4GVmTW79bIjDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMhQuaInQOtSWVn8T6JNmzYltXfffbelpwMAANDq2JEGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMjg1O6V1BprFH8Gsssuu5Q9xp133llSO/XUU8t+/ty5cwvrl1xySdljAAAArGzsSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADA4bW0mdfvrpTR5j8ODBTXp+XV1dYX348OGF9YkTJzbp9QAAAFoDO9IAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABmc2r0aePDBBwvrPXv2LKl17dq1hWcDAACwcrMjDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyOGxsJXXmmWcW1k8//fSS2sCBAwt7x40bV1IbNWpU0yYWERMnTmzyGAAAAK2VHWkAAADIIEgDAABABkEaAAAAMgjSAAAAkEGQBgAAgAxO7V5JLVmypLA+f/78klptbW1h72abbVZS++c//1nYu/XWW5fUHnnkkU+bIgAAwCrJjjQAAABkEKQBAAAggyANAAAAGQRpAAAAyOCwsVXM+eefX1IbNWpUYe+BBx5YUhs3blxh72233dakeQEAAKwq7EgDAABABkEaAAAAMgjSAAAAkEGQBgAAgAyCNAAAAGRwavdq4KWXXiqsr7feeiW1bt26Ffa+/PLLzTonAACAlZUdaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQwWFjq5hjjz22pNaxY8eynz9y5MjC+t13311Su+eee8oeFwAAYFVhRxoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIINTu1cxlZUt8y3daKONSmq9evUq7H3mmWdaZA4AALR+c+bMKaz/6le/KnuMvffeu6S27bbbLvOcoLnZkQYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyODUbsqy8cYbl9Tefvvtwl6ndgPAquekk04qu3f8+PGF9ddee625pkMrdtFFFzV5jMmTJ5fUttxyy8Leyy+/vKQ2dOjQwt5NNtmkaROD/2NHGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcNgYZfnb3/5WUps2bdrynwgA8KkGDhzY5DH22GOPJj3/qKOOKqxPmDChpPbcc8816bVofRYvXtwi444dO7bs3pRSi8wBlrIjDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQwandq5jzzz+/pPad73ynsHedddYpqU2dOrWw9957723SvACA5jVq1KgVPQWA1ZYdaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQwWFjq4GiQ8Ua41AxAGh9evXqVXbvyy+/XFJ78cUXs16vbdu2JbXPfe5zWWMUmT9/fpPHoPVr7KDb3/72t2WPMWDAgJLajBkzCns///nPl9Ry/puBZWFHGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAgg1O7VzEjR44su3fy5MkltZ133rmwt3///iW1J554orD3L3/5S9lzAAA+2wEHHFB274QJE0pqixYtynq9NdYo3WvJObW7aA4REa+++mrWPFg5bbjhhoX1k046qaT22muvFfaOHz++7Nc78MADy+6F5mJHGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcNjYSqroEJCIiG7dupU9xowZM0pqo0aNKvv52267bWHdYWMA0LwqK8t/y5Z7sFiRJUuWlNTGjRvX5HFZva299toltffee6/s5xcdfhvR+PtiaEn+1QEAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZHBq90rq9NNPL7v3sssuK6wfdNBBzTWdBoYPH15YnzhxYou8HgCs6p599tmS2sYbb7wCZgLL7vnnny+pXXrppWU//4UXXmjO6UCT2JEGAACADII0AAAAZBCkAQAAIIMgDQAAABkcNrYa+Na3vrWipwAAlKFXr16F9ZyDxUaNGlVSGz9+fGHvf/7zn7LHhabKOVisyBtvvFFYnzt3bkmtrq6uSa8Fn8WONAAAAGQQpAEAACCDIA0AAAAZBGkAAADIIEgDAABABqd2r6TOPPPMwvrpp59e9hgXX3xxSe173/veMs9pqYkTJzZ5DABYHe28884tMu7WW29dWHdqNy1h9OjRK3oK0OLsSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZHBq90pqyZIlhfVx48Y1adzJkycX1nv16lVSu/7665v0WgDA8tG/f//CeocOHQrrfgMHTTF27NjCutO8WZXYkQYAAIAMgjQAAABkEKQBAAAggyANAAAAGRw2RgMzZszIqgMArd8jjzxSWL/55puX80xYnX3lK18pqTXHv8HOnTs3eQzIZUcaAAAAMgjSAAAAkEGQBgAAgAyCNAAAAGQQpAEAACCDU7sBAFqJyy67rLB+/PHHl9Rqa2sLe+fNm1dSczo3rcGgQYNKaj179izs/eUvf1lSO/DAAwt727Rp06R5wbKwIw0AAAAZBGkAAADIIEgDAABABkEaAAAAMjhsDACglausLP8t24UXXtiCM4EV55prrims9+vXbznPBOxIAwAAQBZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcGo3AEAr0b1798J6TU1N2WP06tWrpPb2228X9s6ZM6fscVl5zZ49u7A+fvz4ssc46aSTCutrr7122WMsXLiwpPbLX/6ysLeioqKkNnr06LJfC1qaHWkAAADIIEgDAABABkEaAAAAMgjSAAAAkMFhYwAArcTw4cPL7p0/f35h/ZBDDim79/zzzy/79Vg5LFmypKT2+9//vsnjXnbZZYX1Dh06lD3GO++8U3bvt7/97ZJaVVVV2c+HlmZHGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAgg1O7AQBWgOOPP76klnMqcW1tbZN7GzslfOLEiWWPTetXdJJ3rtdffz2r3lQbbrhhi4wLzcWONAAAAGQQpAEAACCDIA0AAAAZBGkAAADI4LAxAABgmRxxxBFNev4mm2zSTDOB5cuONAAAAGQQpAEAACCDIA0AAAAZBGkAAADIIEgDAABABqd2AwCsAC+99FJJ7a9//Wth74ABA0pqgwcPbvIc5s6d2+QxaF3WWKN0n2zs2LGFvb/73e/KHvfb3/72Ms8JVkV2pAEAACCDIA0AAAAZBGkAAADIIEgDAABABkEaAAAAMji1GwBgBZg0aVLZvXfeeWdJrWvXroW9m266aUnt2WefLeydMmVK2XNg1eMkblh2dqQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAaHjQEArIRyDisDoHnZkQYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyFC5oicAsKpasGBBSW3hwoWFvXV1dS09HQAAmokdaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADE7tBmii6dOnF9Zvvvnmssfo06dPSe3LX/5yYe9f/vKXssc96KCDyu4FAKA8dqQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAZBGgAAADI4tRugiXJO527Mk08+WVYt17Bhw0pqdXV1TR4XAGB1ZkcaAAAAMgjSAAAAkEGQBgAAgAyCNAAAAGRw2BhAK7XffvsV1m+88cblPBMAAD7OjjQAAABkEKQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAandgM00YABAwrrM2bMKHuMPn36lNS6deu2jDP6SMeOHZs8BgAADdmRBgAAgAyCNAAAAGQQpAEAACCDIA0AAAAZHDYG0ET7779/YT3nsLHDDjuspDZ69Oiyn3/GGWeU3QsAQNPYkQYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyODUboAWMnbs2LJ7Z82aVXZvu3btSmprrOFzUQCA5cU7LwAAAMggSAMAAEAGQRoAAAAyCNIAAACQwWFjAK3A9OnTy+497bTTWnAmAAB8FjvSAAAAkEGQBgAAgAyCNAAAAGQQpAEAACCDIA0AAAAZnNoNsByNHj26RcY444wzCnvXWMPnpQAAzc07LAAAAMggSAMAAEAGQRoAAAAyCNIAAACQwWFjAC3ktttuW9FTAACgBdiRBgAAgAyCNAAAAGQQpAEAACCDIA0AAAAZBGkAAADI4NRugBbywAMPrOgpAADQAuxIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcGo3QAsZM2ZMSW306NErYCYAADQnO9IAAACQQZAGAACADII0AAAAZBCkAQAAIIPDxgCWo7FjxxbWcw4ha2wMAACWDzvSAAAAkEGQBgAAgAyCNAAAAGQQpAEAACCDIA0AAAAZnNoN0AoMHz68pDZx4sTC3rPOOqukdtpppzX7nAAAKGZHGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcNgYQAsZPXp02b1jx44tu3fhwoUltSVLlhT2rrGGz0sBAJqbd1gAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABmc2g3QRNdff32Tx5gwYUJJ7aijjirsveiii0pqY8aMKezNOQ0cAIDy2JEGAACADII0AAAAZBCkAQAAIIMgDQAAABkcNgbQRDNmzGjyGE8++WRJ7bDDDmvyuG+88UZJra6ursnjAgCszuxIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkcGo3QCs1evToFT0FAAAK2JEGAACADII0AAAAZBCkAQAAIIMgDQAAABkcNgbQRAMGDCisz5gxo+wxevfuXVLbeeedC3svvfTSssft2LFj2b0AAJTHjjQAAABkEKQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAandgM00f77719Y32KLLUpqTz/9dGHvXnvtVfbrjR07tuxeAACanx1pAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMTu0GaCF9+vQpqwYAwMrFjjQAAABkEKQBAAAggyANAAAAGQRpAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAgQ+WKnsDKqHPnziW1du3aNXnc6urqwnr37t2bPDbAsurYsWNZtYiIhQsXltTmzZvXzDOC8lmzgdWJNXv5sSMNAAAAGQRpAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMgjQAAABkEKQBAAAggyANAAAAGQRpAAAAyFC5oifAR957773C+rx585bzTIBVWefOnQvra6655nKeCay8rNnA8mDNbr3sSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADA4ba0VSSoX1xYsXL+eZAKuyxv5fA5TPmg0sD9bs1suONAAAAGQQpAEAACCDIA0AAAAZBGkAAADIIEgDAABABqd2L4M333yzpPbWW281eVyn8gHLw9y5c1f0FGC5sWYDKzNrdutlRxoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIINTu5fBBx98sKKnwDKaN29eSe3+++8v7B0yZEhh/fXXXy+pTZs2rbB38ODBJbXp06cX9h500EEltT/96U+FvVtttVVJ7f333y/sra2tLawvXry4pLZo0aLC3iJt2rQprPfo0aOktnDhwsLedu3alf16AMvCmr3ysmZ/xJoNrY8daQAAAMggSAMAAEAGQRoAAAAyCNIAAACQwWFjrFZmz55dUis6zCQiYu7cuYX1ooM5GnPXXXeV1Bo7SOSKK64oqQ0fPrywd9asWSW1hx9+uLB30003LazPmTOnpNbYASPz588vqdXU1BT23nfffSW17bbbrrA351oCsHqxZn/Emg2tjx1pAAAAyCBIAwAAQAZBGgAAADII0gAAAJBBkAYAAIAMTu1mtdKpU6eS2pAhQwp7Gzvh8v777y+pde/evbB38eLFJbXq6urC3h122KGwXmSttdYqqXXr1q2wt127doX1ov4333yzsLdr164ltcrK4v99FF3PV199tbAXABpjzf70fms2rFh2pAEAACCDIA0AAAAZBGkAAADIIEgDAABABoeNsVrp1atXk8coOsRjeevRo0dZtdaiNVwzAFYu1uwVozVcM1gZ2JEGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIIMgDQAAABkEaQAAAMggSAMAAEAGQRoAAAAyCNIAAACQQZAGAACADII0AAAAZBCkAQAAIENFSimt6EkAAADAysKONAAAAGQQpAEAACCDIA0AAAAZBGkAAADIIEgDAABABkEaAAAAMgjSAAAAkEGQBgAAgAyCNAAAAGT4/8zH9ggq8m/sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reset the environment\n",
    "observations = parallel_env.reset()\n",
    "\n",
    "# Initialize a variable to store observations\n",
    "step_1_observation = None\n",
    "step_100_observation = None\n",
    "\n",
    "for step in range(8000):\n",
    "    # Sample random actions for all agents\n",
    "    actions = {agent: parallel_env.action_space(agent).sample() for agent in parallel_env.agents}\n",
    "\n",
    "    # Step the environment\n",
    "    step_output = parallel_env.step(actions)\n",
    "\n",
    "    if len(step_output) == 5:  # Handle truncations\n",
    "        next_observations, rewards, dones, truncations, infos = step_output\n",
    "        dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "    else:\n",
    "        next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "    # Store the first and 100th observations\n",
    "    if step == 0:\n",
    "        step_1_observation = next_observations.copy()\n",
    "    if step == 5999:\n",
    "        print(f\"rewards at 5999: {rewards}\")\n",
    "        step_100_observation = next_observations.copy()\n",
    "\n",
    "    # Break if the environment is done\n",
    "    if all(dones.values()):\n",
    "        break\n",
    "\n",
    "# Visualize the observations for the first and 100th steps\n",
    "agent = list(next_observations.keys())[0]  # Pick the first agent for visualization\n",
    "\n",
    "# Convert the observations to grayscale if they are in RGB format\n",
    "def preprocess_observation(obs):\n",
    "    if len(obs.shape) == 3 and obs.shape[-1] == 3:  # RGB format\n",
    "        obs = np.mean(obs, axis=-1)  # Convert to grayscale\n",
    "    return obs\n",
    "\n",
    "step_1_frame = preprocess_observation(step_1_observation[agent])\n",
    "step_100_frame = preprocess_observation(step_100_observation[agent])\n",
    "\n",
    "# Plot the frames\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Step 1 observation\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(step_1_frame, cmap='gray')\n",
    "plt.title(\"Step 1 Observation\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Step 100 observation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(step_100_frame, cmap='gray')\n",
    "plt.title(\"Step 100 Observation\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for agent, obs in next_observations.items():\n",
    "    plt.imshow(obs)  # Assuming observations are raw frames\n",
    "    plt.title(f\"Agent: {agent}\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample actions for all agents based on the processed observation keys\n",
    "actions = {agent: env.action_space(agent).sample() for agent in observations.keys()}\n",
    "print(f\"Sampled Actions: {actions}\")\n",
    "\n",
    "# Ensure actions match the agents in the environment\n",
    "if set(actions.keys()) != set(env.agents):\n",
    "    raise ValueError(f\"Mismatch between action keys and environment agents: {actions.keys()} vs {env.agents}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment\n",
    "observations = env.reset()\n",
    "\n",
    "# Handle nested observations if necessary\n",
    "if isinstance(observations, tuple) and len(observations) > 0:\n",
    "    observations = observations[0]\n",
    "\n",
    "if not isinstance(observations, dict):\n",
    "    raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "# Sample actions for all agents\n",
    "actions = {agent: env.action_space(agent).sample() for agent in observations.keys()}\n",
    "print(f\"Sampled Actions: {actions}\")\n",
    "\n",
    "# Step the environment with actions for all agents\n",
    "try:\n",
    "    obs, rewards, dones, truncations, infos = env.step(actions)\n",
    "except TypeError as e:\n",
    "    print(f\"Step Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Print results\n",
    "for agent, action in actions.items():\n",
    "    print(f\"Agent: {agent}, Action: {action}\")\n",
    "print(f\"Rewards: {rewards}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for episode in range(num_episodes):\n",
    "#     # Reset the environment\n",
    "#     observations = parallel_env.reset()\n",
    "\n",
    "#     # Extract nested observations (first element of the tuple)\n",
    "#     if isinstance(observations, tuple) and len(observations) > 0:\n",
    "#         agent_observations = observations[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "#     # Initialize done flags for each agent\n",
    "#     done = {agent: False for agent in agent_observations.keys()}\n",
    "#     step = 0\n",
    "\n",
    "#     while not all(done.values()) and step < max_steps_per_episode:\n",
    "#         actions = {}\n",
    "#         log_probs = {}\n",
    "\n",
    "#         # Process observations for each agent\n",
    "#         for agent, obs in agent_observations.items():\n",
    "#             # Convert observations to grayscale if needed\n",
    "#             if obs.shape[-1] == 3:  # If RGB format\n",
    "#                 obs = obs.mean(axis=-1)  # Convert to grayscale by averaging RGB channels\n",
    "\n",
    "#             # Prepare tensor with correct dimensions\n",
    "#             obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "\n",
    "#             # Get action probabilities\n",
    "#             action_probs = ppo.policy.forward_policy(obs_tensor)\n",
    "#             action = torch.multinomial(action_probs, 1).item()  # Sample action\n",
    "#             log_probs[agent] = torch.log(action_probs.squeeze(0)[action])  # Log probability\n",
    "#             actions[agent] = action  # Store action\n",
    "\n",
    "#         # Step the environment\n",
    "#         step_output = parallel_env.step(actions)\n",
    "\n",
    "#         if len(step_output) == 5:  # Handle truncations\n",
    "#             next_observations, rewards, dones, truncations, infos = step_output\n",
    "#             dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "#         else:\n",
    "#             next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "#         # Extract nested observations for next step\n",
    "#         if isinstance(next_observations, dict):\n",
    "#             agent_observations = next_observations  # Observations are already in dictionary format\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unexpected observation structure after step: {type(next_observations)}\")\n",
    "\n",
    "\n",
    "#         # Store data in the buffer for each agent\n",
    "#         for agent, obs in agent_observations.items():\n",
    "#             buffer.store(obs, actions[agent], log_probs[agent].item(), rewards[agent], dones[agent])\n",
    "\n",
    "#         # Update done flags\n",
    "#         done = dones\n",
    "#         step += 1\n",
    "\n",
    "#     # Compute Returns and Advantages\n",
    "#     print(f\"Episode {episode + 1}: Computing returns and advantages...\")\n",
    "#     buffer.compute_returns_and_advantages(ppo.policy, ppo.gamma, ppo.gae_lambda)\n",
    "\n",
    "#     # Update PPO\n",
    "#     print(f\"Episode {episode + 1}: Updating PPO model...\")\n",
    "#     ppo.update(buffer)\n",
    "\n",
    "#     # Clear buffer for the next episode\n",
    "#     buffer.clear()\n",
    "\n",
    "#     # Log progress\n",
    "#     print(f\"Episode {episode + 1}/{num_episodes} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS153",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
