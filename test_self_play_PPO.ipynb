{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Non-stack Version of PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pettingzoo.atari import boxing_v2\n",
    "import numpy as np\n",
    "import random \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from supersuit import pad_observations_v0, pad_action_space_v0, resize_v1, normalize_obs_v0, frame_skip_v0, dtype_v0\n",
    "from pettingzoo.utils import aec_to_parallel\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RolloutBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutBuffer:\n",
    "    \"\"\"\n",
    "    Buffer to store rollout data for PPO.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.returns = []\n",
    "        self.advantages = []\n",
    "\n",
    "    def store(self, obs, action, log_prob, reward, done):\n",
    "        if obs.shape[-1] == 3:  # If observation has RGB channels\n",
    "            obs = obs.mean(axis=-1)  # Convert to grayscale\n",
    "        self.observations.append(obs)\n",
    "        self.actions.append(action)\n",
    "        self.log_probs.append(log_prob)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "\n",
    "    def compute_returns_and_advantages(self, policy, gamma, gae_lambda):\n",
    "        \"\"\"\n",
    "        Computes returns and advantages using Generalized Advantage Estimation (GAE).\n",
    "\n",
    "        Parameters:\n",
    "        policy (PPOAgent): The policy network.\n",
    "        gamma (float): Discount factor for rewards.\n",
    "        gae_lambda (float): Lambda parameter for GAE.\n",
    "        \"\"\"\n",
    "        if not self.observations:  # Guard clause\n",
    "            print(\"Warning: Buffer is empty. Skipping returns and advantages computation.\")\n",
    "            self.returns = []\n",
    "            self.advantages = []\n",
    "            return\n",
    "        \n",
    "        values = [\n",
    "            policy.forward_value(\n",
    "                torch.tensor(\n",
    "                    obs[np.newaxis, np.newaxis, :, :],  # Add batch and channel dimensions (1, 1, H, W)\n",
    "                    dtype=torch.float32\n",
    "                ) / 255.0  # Normalize\n",
    "            ).item()\n",
    "            for obs in self.observations\n",
    "        ]\n",
    "\n",
    "\n",
    "        next_value = 0 if self.dones[-1] else values[-1]\n",
    "\n",
    "        # GAE computation\n",
    "        returns = []\n",
    "        advantages = []\n",
    "        gae = 0\n",
    "        for step in reversed(range(len(self.rewards))):\n",
    "            delta = self.rewards[step] + gamma * next_value * (1 - self.dones[step]) - values[step]\n",
    "            gae = delta + gamma * gae_lambda * (1 - self.dones[step]) * gae\n",
    "            advantages.insert(0, gae)\n",
    "            next_value = values[step]\n",
    "            returns.insert(0, gae + values[step])\n",
    "\n",
    "        self.returns = returns\n",
    "        self.advantages = advantages\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Clears the buffer.\n",
    "        \"\"\"\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.returns = []\n",
    "        self.advantages = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO Agent(Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(nn.Module):\n",
    "    def __init__(self, obs_shape, action_space):\n",
    "        super(PPOAgent, self).__init__()\n",
    "        \n",
    "        # Convolutional layers adapted for single-channel input\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(obs_shape[0], 32, kernel_size=8, stride=4),  # obs_shape[0] is the channel size\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Dynamically calculate the feature map size\n",
    "        feature_map_size = self.calculate_feature_map_size(obs_shape)\n",
    "        \n",
    "        # Policy network\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_map_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_space.n),\n",
    "        )\n",
    "        \n",
    "        # Value network\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_map_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward_policy(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the policy network.\n",
    "        Converts the observation to a probability distribution over actions.\n",
    "        \"\"\"\n",
    "        x = self.conv_layers(x)\n",
    "        return torch.softmax(self.policy_net(x), dim=-1)\n",
    "\n",
    "    def forward_value(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the value network.\n",
    "        Converts the observation to an estimated value.\n",
    "        \"\"\"\n",
    "        x = self.conv_layers(x)\n",
    "        return self.value_net(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Default forward method for compatibility in opponent policy.\n",
    "        Delegates to forward_policy to output action probabilities.\n",
    "        \"\"\"\n",
    "        return self.forward_policy(x)\n",
    "\n",
    "    def calculate_feature_map_size(self, input_shape):\n",
    "        \"\"\"\n",
    "        Calculates the feature map size after the convolutional layers.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)  # Batch size of 1\n",
    "            output = self.conv_layers(dummy_input)\n",
    "            print(\"Shape after conv layers:\", output.size())  # Debugging output shape\n",
    "        return int(np.prod(output.size()[1:]))  # Flatten the output shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PPO:\n",
    "    \"\"\"\n",
    "    Proximal Policy Optimization (PPO) implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_shape, action_space, lr=3e-4, gamma=0.9, epsilon=0.2, gae_lambda=0.95):\n",
    "        self.policy = PPOAgent(obs_shape, action_space)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "    def update(self, buffer):\n",
    "        \"\"\"\n",
    "        Updates the policy and value networks using PPO loss.\n",
    "\n",
    "        Parameters:\n",
    "        buffer (RolloutBuffer): The buffer containing rollout data.\n",
    "        \"\"\"\n",
    "        policy_losses = []\n",
    "        value_losses = []\n",
    "        total_losses = []\n",
    "        \n",
    "        obs_array = np.array(buffer.observations, dtype=np.float32)  # Combine into a single numpy array\n",
    "        \n",
    "        \"\"\"\n",
    "        None Skipping version\n",
    "        \"\"\"\n",
    "        if len(obs_array.shape) == 3:  # Handle grayscale observations (Batch, H, W)\n",
    "            obs = torch.tensor(obs_array, dtype=torch.float32).unsqueeze(1) / 255.0  # Add channel dim (Batch, 1, H, W)\n",
    "        else:  # If stacking was used and there are 4D observations\n",
    "            obs = torch.tensor(obs_array, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # (Batch, Channels, H, W)\n",
    "        # print(f\"Observation Shape in Update: {obs.shape}\")  # Debug shape\n",
    "        \"\"\"\n",
    "        Skipping version\n",
    "        \"\"\"\n",
    "        # if len(obs_array.shape) == 3:  # Single-frame observations\n",
    "        #     obs = torch.tensor(obs_array, dtype=torch.float32).unsqueeze(1) / 255.0  # Add channel dim\n",
    "        # elif len(obs_array.shape) == 4:  # Stacked observations\n",
    "        #     obs = torch.tensor(obs_array, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0  # (Batch, Channels, H, W)\n",
    "        # else:\n",
    "        #     raise ValueError(f\"Unexpected observation shape after skip: {obs_array.shape}\")\n",
    "\n",
    "        # print(f\"Observation Shape in Update: {obs.shape}\")\n",
    "        \n",
    "        actions = torch.tensor(buffer.actions, dtype=torch.int64)\n",
    "        old_log_probs = torch.tensor(buffer.log_probs, dtype=torch.float32)\n",
    "        returns = torch.tensor(buffer.returns, dtype=torch.float32)\n",
    "        advantages = torch.tensor(buffer.advantages, dtype=torch.float32)\n",
    "\n",
    "        for _ in range(10):  # Number of PPO epochs\n",
    "            # Get new log probabilities and values\n",
    "            new_probs = self.policy.forward_policy(obs).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "            new_log_probs = torch.log(new_probs + 1e-8)\n",
    "            values = self.policy.forward_value(obs).squeeze(-1)\n",
    "            # print(f\"Values Shape in Update: {values.shape}\")\n",
    "\n",
    "            # Compute the ratio\n",
    "            ratio = torch.exp(new_log_probs - old_log_probs)\n",
    "\n",
    "            # Compute the clipped surrogate objective\n",
    "            surr1 = ratio * advantages\n",
    "            surr2 = torch.clamp(ratio, 1 - self.epsilon, 1 + self.epsilon) * advantages\n",
    "            policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            value_loss = nn.MSELoss()(values, returns)\n",
    "\n",
    "            # Total loss\n",
    "            loss = policy_loss + 0.5 * value_loss\n",
    "\n",
    "            policy_losses.append(policy_loss.item())\n",
    "            value_losses.append(value_loss.item())\n",
    "            total_losses.append(loss.item())\n",
    "            \n",
    "            # Gradient update\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        print(f\"Policy Loss: {np.mean(policy_losses)}, Value Loss: {np.mean(value_losses)}, Total Loss: {np.mean(total_losses)}\")\n",
    "\n",
    "        return policy_losses, value_losses, total_losses\n",
    "\n",
    "    def save_policy_network(self, save_path):\n",
    "        torch.save(self.policy.policy_net.state_dict(), save_path)\n",
    "        print(f\"Policy network saved to {save_path}\")\n",
    "\n",
    "    def save_value_network(self, save_path):\n",
    "        torch.save(self.policy.value_net.state_dict(), save_path)\n",
    "        print(f\"Value network saved to {save_path}\")\n",
    "        \n",
    "    def load_policy_network(self, load_path):\n",
    "        loaded_state_dict = torch.load(load_path)\n",
    "        # Filter keys to match `policy_net`\n",
    "        filtered_state_dict = {k.replace(\"policy_net.\", \"\"): v for k, v in loaded_state_dict.items() if \"policy_net.\" in k}\n",
    "        self.policy.policy_net.load_state_dict(filtered_state_dict)\n",
    "        print(f\"Policy network loaded from {load_path}\")\n",
    "\n",
    "    def load_value_network(self, load_path):\n",
    "        loaded_state_dict = torch.load(load_path)\n",
    "        # Filter keys to match `value_net`\n",
    "        filtered_state_dict = {k.replace(\"value_net.\", \"\"): v for k, v in loaded_state_dict.items() if \"value_net.\" in k}\n",
    "        self.policy.value_net.load_state_dict(filtered_state_dict)\n",
    "        print(f\"Value network loaded from {load_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = \"ppo_trained_models_Dec_11\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# File paths for saving\n",
    "policy_model_path = os.path.join(save_dir, \"ppo_policy_model.pth\")\n",
    "value_model_path = os.path.join(save_dir, \"ppo_value_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Set up the environment\n",
    "# env = boxing_v2.env(render_mode=\"rgb_array\")\n",
    "# env.reset(seed=42)\n",
    "# env = pad_observations_v0(env)\n",
    "# env = pad_action_space_v0(env)\n",
    "# env = resize_v1(env, 84, 84)  # Resize frames to 84x84\n",
    "# env = dtype_v0(env, dtype=\"float32\")  # Convert observations to float32\n",
    "# env = normalize_obs_v0(env, env_min=0, env_max=1)  # Normalize pixel values\n",
    "\n",
    "# parallel_env = aec_to_parallel(env)  # Convert to parallel format\n",
    "\n",
    "# # Step 2: Initialize PPO and RolloutBuffer\n",
    "# obs_shape = (1, 84, 84)  # Single frame (no stacking)\n",
    "# action_space = env.action_space(\"first_0\")  # Example action space for an agent\n",
    "# ppo = PPO(obs_shape, action_space)\n",
    "\n",
    "# # Load pre-trained models\n",
    "# # ppo.load_value_network(value_model_path)  # load value network\n",
    "# # ppo.load_policy_network(policy_model_path) # load policy network\n",
    "\n",
    "# # Initialize the buffer\n",
    "# buffer = RolloutBuffer()\n",
    "\n",
    "# # Step 3: Training Loop\n",
    "# num_episodes = 1\n",
    "# max_steps_per_episode = 5000  # Maximum steps to prevent infinite loops\n",
    "# # Initialize reward tracking\n",
    "# cumulative_rewards = []\n",
    "\n",
    "# for episode in range(num_episodes):\n",
    "#     # Reset the environment\n",
    "#     observations = parallel_env.reset()\n",
    "\n",
    "#     # Extract nested observations (first element of the tuple)\n",
    "#     if isinstance(observations, tuple) and len(observations) > 0:\n",
    "#         agent_observations = observations[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "#     # Initialize done flags for each agent\n",
    "#     done = {agent: False for agent in agent_observations.keys()}\n",
    "#     step = 0\n",
    "#     episode_reward = defaultdict(int)  # Track total reward for the episode\n",
    "\n",
    "#     while not all(done.values()) and step < max_steps_per_episode:\n",
    "#         actions = {}\n",
    "#         log_probs = {}\n",
    "\n",
    "#         # Process observations for each agent\n",
    "#         for agent, obs in agent_observations.items():\n",
    "#             # Convert observations to grayscale if needed\n",
    "#             if obs.shape[-1] == 3:  # If RGB format\n",
    "#                 obs = obs.mean(axis=-1)  # Convert to grayscale by averaging RGB channels\n",
    "\n",
    "#             # Prepare tensor\n",
    "#             obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "\n",
    "#             # Get action probabilities\n",
    "#             action_probs = ppo.policy.forward_policy(obs_tensor)\n",
    "#             action = torch.multinomial(action_probs, 1).item()  # Sample action\n",
    "#             log_probs[agent] = torch.log(action_probs.squeeze(0)[action])  # Log probability\n",
    "#             actions[agent] = action  # Store action\n",
    "\n",
    "#         # Step the environment\n",
    "#         step_output = parallel_env.step(actions)\n",
    "\n",
    "#         if len(step_output) == 5:  # Handle truncations\n",
    "#             next_observations, rewards, dones, truncations, infos = step_output\n",
    "#             dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "#             # print(f\"observations: {next_observations}\")\n",
    "#         else:\n",
    "#             next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "#         # Extract nested observations for next step\n",
    "#         if isinstance(next_observations, dict):\n",
    "#             agent_observations = next_observations  # Observations are already in dictionary format\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unexpected observation structure after step: {type(next_observations)}\")\n",
    "\n",
    "\n",
    "#         for agent, reward in rewards.items():\n",
    "#             # if reward != 0:\n",
    "#             #     print(f\"Agent: {agent}, Reward: {reward}\")\n",
    "#             episode_reward[agent] += reward\n",
    "        \n",
    "#         # Store data in the buffer for each agent\n",
    "#         for agent, obs in agent_observations.items():\n",
    "#             # print(f\"Agent: {agent}, Reward: {rewards[agent]}\")\n",
    "#             buffer.store(obs, actions[agent], log_probs[agent].item(), rewards[agent], dones[agent])\n",
    "\n",
    "#         # Update done flags\n",
    "#         done = dones\n",
    "#         step += 1\n",
    "\n",
    "#     # Append episode reward\n",
    "#     cumulative_rewards.append(episode_reward)\n",
    "\n",
    "#     # Compute Returns and Advantages\n",
    "#     print(f\"Episode {episode + 1}: Episode Reward = {episode_reward}\")\n",
    "#     buffer.compute_returns_and_advantages(ppo.policy, ppo.gamma, ppo.gae_lambda)\n",
    "\n",
    "#     # Update PPO\n",
    "#     print(f\"Episode {episode + 1}: Updating PPO model...\")\n",
    "#     policy_losses, value_losses, total_losses = ppo.update(buffer)\n",
    "\n",
    "#     # Clear buffer for the next episode\n",
    "#     buffer.clear()\n",
    "\n",
    "#     # Log progress\n",
    "#     print(f\"Episode {episode + 1}/{num_episodes} completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Episode 1: Episode Reward = defaultdict(<class 'int'>, {'first_0': -1, 'second_0': 1})\n",
      "Episode 1: Updating PPO model...\n",
      "Policy Loss: 0.010213390924036503, Value Loss: 0.0032149838400073348, Total Loss: 0.011820882745087146\n",
      "Episode 1/50 completed.\n",
      "Episode 2: Episode Reward = defaultdict(<class 'int'>, {'first_0': -2, 'second_0': 2})\n",
      "Episode 2: Updating PPO model...\n",
      "Policy Loss: 0.02150588985532522, Value Loss: 0.0016299745999276637, Total Loss: 0.02232087720185518\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 2\n",
      "Episode 2/50 completed.\n",
      "Episode 3: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 3: Updating PPO model...\n",
      "Policy Loss: 0.0009696127206552773, Value Loss: 2.455995256500643e-07, Total Loss: 0.0009697355213575065\n",
      "Episode 3/50 completed.\n",
      "Episode 4: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 4: Updating PPO model...\n",
      "Policy Loss: 0.00043457304418552666, Value Loss: 0.0004313916841056198, Total Loss: 0.0006502688862383366\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 4\n",
      "Episode 4/50 completed.\n",
      "Episode 5: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 5: Updating PPO model...\n",
      "Policy Loss: -1.5110061872292135e-05, Value Loss: 0.003666107356548309, Total Loss: 0.0018179436097852885\n",
      "Episode 5/50 completed.\n",
      "Episode 6: Episode Reward = defaultdict(<class 'int'>, {'first_0': 1, 'second_0': -1})\n",
      "Episode 6: Updating PPO model...\n",
      "Policy Loss: -0.00023878884530859068, Value Loss: 0.00010784211262944154, Total Loss: -0.0001848677871748805\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 6\n",
      "Episode 6/50 completed.\n",
      "Episode 7: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 7: Updating PPO model...\n",
      "Policy Loss: -5.2544155187206344e-05, Value Loss: 5.340771053186088e-09, Total Loss: -5.254148527455982e-05\n",
      "Episode 7/50 completed.\n",
      "Episode 8: Episode Reward = defaultdict(<class 'int'>, {'first_0': -3, 'second_0': 3})\n",
      "Episode 8: Updating PPO model...\n",
      "Policy Loss: -9.297568863075866e-06, Value Loss: 0.0005391206010244787, Total Loss: 0.00026026272971648725\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 8\n",
      "Episode 8/50 completed.\n",
      "Episode 9: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 9: Updating PPO model...\n",
      "Policy Loss: 8.16034633317031e-05, Value Loss: 3.3502211810310102e-09, Total Loss: 8.160513898474165e-05\n",
      "Episode 9/50 completed.\n",
      "Episode 10: Episode Reward = defaultdict(<class 'int'>, {'first_0': -1, 'second_0': 1})\n",
      "Episode 10: Updating PPO model...\n",
      "Policy Loss: 8.43204434204381e-05, Value Loss: 0.00010781911987578496, Total Loss: 0.00013823000335833058\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 10\n",
      "Episode 10/50 completed.\n",
      "Episode 11: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 11: Updating PPO model...\n",
      "Policy Loss: 1.5471846018044745e-05, Value Loss: 1.765714588430889e-10, Total Loss: 1.5471934784727636e-05\n",
      "Episode 11/50 completed.\n",
      "Episode 12: Episode Reward = defaultdict(<class 'int'>, {'first_0': -3, 'second_0': 3})\n",
      "Episode 12: Updating PPO model...\n",
      "Policy Loss: -2.6351735505159014e-05, Value Loss: 0.0005390935693867505, Total Loss: 0.00024319504882441834\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 12\n",
      "Episode 12/50 completed.\n",
      "Episode 13: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 13: Updating PPO model...\n",
      "Policy Loss: -4.518874593486544e-05, Value Loss: 5.236295995240947e-09, Total Loss: -4.518612768151797e-05\n",
      "Episode 13/50 completed.\n",
      "Episode 14: Episode Reward = defaultdict(<class 'int'>, {'first_0': 1, 'second_0': -1})\n",
      "Episode 14: Updating PPO model...\n",
      "Policy Loss: -7.40913710615132e-05, Value Loss: 0.0001078183195204474, Total Loss: -2.01822113012895e-05\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 14\n",
      "Episode 14/50 completed.\n",
      "Episode 15: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 15: Updating PPO model...\n",
      "Policy Loss: -5.337304937711451e-05, Value Loss: 1.6931497481831315e-09, Total Loss: -5.337220354704186e-05\n",
      "Episode 15/50 completed.\n",
      "Episode 16: Episode Reward = defaultdict(<class 'int'>, {'first_0': -12, 'second_0': 12})\n",
      "Episode 16: Updating PPO model...\n",
      "Policy Loss: -0.00010754452741821297, Value Loss: 0.002155716577544808, Total Loss: 0.0009703137504402549\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 16\n",
      "Episode 16/50 completed.\n",
      "Episode 17: Episode Reward = defaultdict(<class 'int'>, {'first_0': 1, 'second_0': -1})\n",
      "Episode 17: Updating PPO model...\n",
      "Policy Loss: -0.0001481315412092954, Value Loss: 0.0011861214763484896, Total Loss: 0.00044492919114418327\n",
      "Episode 17/50 completed.\n",
      "Episode 18: Episode Reward = defaultdict(<class 'int'>, {'first_0': -4, 'second_0': 4})\n",
      "Episode 18: Updating PPO model...\n",
      "Policy Loss: 6.373179112415528e-05, Value Loss: 0.0017254979349672795, Total Loss: 0.0009264807566069066\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 18\n",
      "Episode 18/50 completed.\n",
      "Episode 19: Episode Reward = defaultdict(<class 'int'>, {'first_0': -2, 'second_0': 2})\n",
      "Episode 19: Updating PPO model...\n",
      "Policy Loss: -0.000772374274674803, Value Loss: 0.0004315160738769919, Total Loss: -0.0005566162464674563\n",
      "Episode 19/50 completed.\n",
      "Episode 20: Episode Reward = defaultdict(<class 'int'>, {'first_0': -1, 'second_0': 1})\n",
      "Episode 20: Updating PPO model...\n",
      "Policy Loss: -0.00045039651158731433, Value Loss: 0.002912413771264255, Total Loss: 0.001005810359492898\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 20\n",
      "Episode 20/50 completed.\n",
      "Episode 21: Episode Reward = defaultdict(<class 'int'>, {'first_0': -21, 'second_0': 21})\n",
      "Episode 21: Updating PPO model...\n",
      "Policy Loss: 0.0006602543580811471, Value Loss: 0.0029253760585561395, Total Loss: 0.0021229423582553864\n",
      "Episode 21/50 completed.\n",
      "Episode 22: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 22: Updating PPO model...\n",
      "Policy Loss: 0.002320550917647779, Value Loss: 4.6785129114823574e-06, Total Loss: 0.002322890190407634\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 22\n",
      "Episode 22/50 completed.\n",
      "Episode 23: Episode Reward = defaultdict(<class 'int'>, {'first_0': 5, 'second_0': -5})\n",
      "Episode 23: Updating PPO model...\n",
      "Policy Loss: 0.001059458905365318, Value Loss: 0.0009758997068274767, Total Loss: 0.0015474087558686733\n",
      "Episode 23/50 completed.\n",
      "Episode 24: Episode Reward = defaultdict(<class 'int'>, {'first_0': -6, 'second_0': 6})\n",
      "Episode 24: Updating PPO model...\n",
      "Policy Loss: -0.0020861127646639942, Value Loss: 0.0015137771260924637, Total Loss: -0.0013292242074385285\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 24\n",
      "Episode 24/50 completed.\n",
      "Episode 25: Episode Reward = defaultdict(<class 'int'>, {'first_0': -8, 'second_0': 8})\n",
      "Episode 25: Updating PPO model...\n",
      "Policy Loss: -0.0015176377724856137, Value Loss: 0.0021749597741290926, Total Loss: -0.0004301578854210675\n",
      "Episode 25/50 completed.\n",
      "Episode 26: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 26: Updating PPO model...\n",
      "Policy Loss: 0.0028712120605632664, Value Loss: 3.99705661493499e-06, Total Loss: 0.002873210608959198\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 26\n",
      "Episode 26/50 completed.\n",
      "Episode 27: Episode Reward = defaultdict(<class 'int'>, {'first_0': -1, 'second_0': 1})\n",
      "Episode 27: Updating PPO model...\n",
      "Policy Loss: -4.8535886890022084e-05, Value Loss: 0.00010950131836580112, Total Loss: 6.214772292878479e-06\n",
      "Episode 27/50 completed.\n",
      "Episode 28: Episode Reward = defaultdict(<class 'int'>, {'first_0': -6, 'second_0': 6})\n",
      "Episode 28: Updating PPO model...\n",
      "Policy Loss: 0.0001908367994474247, Value Loss: 0.0017264999682083727, Total Loss: 0.0010540867689996958\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 28\n",
      "Episode 28/50 completed.\n",
      "Episode 29: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 29: Updating PPO model...\n",
      "Policy Loss: -0.0007786835252773016, Value Loss: 4.1798447352192626e-07, Total Loss: -0.0007784745248500258\n",
      "Episode 29/50 completed.\n",
      "Episode 30: Episode Reward = defaultdict(<class 'int'>, {'first_0': -1, 'second_0': 1})\n",
      "Episode 30: Updating PPO model...\n",
      "Policy Loss: 3.737151689620077e-06, Value Loss: 0.0005391952930949628, Total Loss: 0.0002733347995672375\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 30\n",
      "Episode 30/50 completed.\n",
      "Episode 31: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 31: Updating PPO model...\n",
      "Policy Loss: 0.0003437254810705781, Value Loss: 2.12535136601133e-08, Total Loss: 0.00034373610687907783\n",
      "Episode 31/50 completed.\n",
      "Episode 32: Episode Reward = defaultdict(<class 'int'>, {'first_0': 2, 'second_0': -2})\n",
      "Episode 32: Updating PPO model...\n",
      "Policy Loss: 0.00029876184707973153, Value Loss: 0.00043724784336518496, Total Loss: 0.0005173857673071325\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 32\n",
      "Episode 32/50 completed.\n",
      "Episode 33: Episode Reward = defaultdict(<class 'int'>, {'first_0': 2, 'second_0': -2})\n",
      "Episode 33: Updating PPO model...\n",
      "Policy Loss: 0.0015271083218976855, Value Loss: 0.0002193175270804204, Total Loss: 0.0016367670963518322\n",
      "Episode 33/50 completed.\n",
      "Episode 34: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 34: Updating PPO model...\n",
      "Policy Loss: 0.0003590331703890115, Value Loss: 6.92240772970365e-07, Total Loss: 0.00035937929060310126\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 34\n",
      "Episode 34/50 completed.\n",
      "Episode 35: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 35: Updating PPO model...\n",
      "Policy Loss: -0.00038961126119829714, Value Loss: 0.00021954081457806752, Total Loss: -0.00027984085609205066\n",
      "Episode 35/50 completed.\n",
      "Episode 36: Episode Reward = defaultdict(<class 'int'>, {'first_0': 1, 'second_0': -1})\n",
      "Episode 36: Updating PPO model...\n",
      "Policy Loss: -0.0013353785034269094, Value Loss: 0.000109116654493846, Total Loss: -0.001280820183455944\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 36\n",
      "Episode 36/50 completed.\n",
      "Episode 37: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 37: Updating PPO model...\n",
      "Policy Loss: -0.00023769865510985254, Value Loss: 3.3548539275507493e-07, Total Loss: -0.00023753091372782364\n",
      "Episode 37/50 completed.\n",
      "Episode 38: Episode Reward = defaultdict(<class 'int'>, {'first_0': 1, 'second_0': -1})\n",
      "Episode 38: Updating PPO model...\n",
      "Policy Loss: 0.00034309688489884136, Value Loss: 0.00010789835650939494, Total Loss: 0.00039704606169834735\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 38\n",
      "Episode 38/50 completed.\n",
      "Episode 39: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 39: Updating PPO model...\n",
      "Policy Loss: -7.598527081427164e-05, Value Loss: 8.308195948575348e-09, Total Loss: -7.598111769766547e-05\n",
      "Episode 39/50 completed.\n",
      "Episode 40: Episode Reward = defaultdict(<class 'int'>, {'first_0': -2, 'second_0': 2})\n",
      "Episode 40: Updating PPO model...\n",
      "Policy Loss: -4.276289837434888e-05, Value Loss: 0.000650417571887374, Total Loss: 0.0002824458875693381\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 40\n",
      "Episode 40/50 completed.\n",
      "Episode 41: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 41: Updating PPO model...\n",
      "Policy Loss: -0.0009352703171316534, Value Loss: 0.00021797803492518142, Total Loss: -0.0008262813033070415\n",
      "Episode 41/50 completed.\n",
      "Episode 42: Episode Reward = defaultdict(<class 'int'>, {'first_0': -3, 'second_0': 3})\n",
      "Episode 42: Updating PPO model...\n",
      "Policy Loss: 1.5721641898380766e-05, Value Loss: 0.0009714764135424047, Total Loss: 0.0005014598573325202\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 42\n",
      "Episode 42/50 completed.\n",
      "Episode 43: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 43: Updating PPO model...\n",
      "Policy Loss: -5.524410335056018e-05, Value Loss: 9.620129571129982e-08, Total Loss: -5.519600272236857e-05\n",
      "Episode 43/50 completed.\n",
      "Episode 44: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 44: Updating PPO model...\n",
      "Policy Loss: -0.000180318602360785, Value Loss: 3.5738282505581866e-08, Total Loss: -0.0001803007340640761\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 44\n",
      "Episode 44/50 completed.\n",
      "Episode 45: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 45: Updating PPO model...\n",
      "Policy Loss: 9.140719266724773e-05, Value Loss: 1.8213913401815552e-09, Total Loss: 9.140810361714102e-05\n",
      "Episode 45/50 completed.\n",
      "Episode 46: Episode Reward = defaultdict(<class 'int'>, {'first_0': 1, 'second_0': -1})\n",
      "Episode 46: Updating PPO model...\n",
      "Policy Loss: 8.6339378322009e-05, Value Loss: 0.00010782262179418468, Total Loss: 0.0001402506895828992\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 46\n",
      "Episode 46/50 completed.\n",
      "Episode 47: Episode Reward = defaultdict(<class 'int'>, {'first_0': -7, 'second_0': 7})\n",
      "Episode 47: Updating PPO model...\n",
      "Policy Loss: -4.9532472257851626e-05, Value Loss: 0.0020477710058912635, Total Loss: 0.0009743530070409178\n",
      "Episode 47/50 completed.\n",
      "Episode 48: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 48: Updating PPO model...\n",
      "Policy Loss: -0.00024795501958578824, Value Loss: 7.68336282985782e-08, Total Loss: -0.00024791660252958535\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 48\n",
      "Episode 48/50 completed.\n",
      "Episode 49: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 49: Updating PPO model...\n",
      "Policy Loss: 0.00013786037161480635, Value Loss: 4.766133481215462e-08, Total Loss: 0.0001378842003759928\n",
      "Episode 49/50 completed.\n",
      "Episode 50: Episode Reward = defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n",
      "Episode 50: Updating PPO model...\n",
      "Policy Loss: -4.204415890853852e-05, Value Loss: 8.55934516250101e-09, Total Loss: -4.203987919026986e-05\n",
      "Shape after conv layers: torch.Size([1, 64, 9, 9])\n",
      "Checkpoint: Saved policy for self-play after Episode 50\n",
      "Episode 50/50 completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Opponent storage\n",
    "opponent_policies = []\n",
    "\n",
    "# Step 1: Set up the environment\n",
    "env = boxing_v2.env(render_mode=\"rgb_array\")\n",
    "env.reset(seed=42)\n",
    "env = pad_observations_v0(env)\n",
    "env = pad_action_space_v0(env)\n",
    "env = resize_v1(env, 84, 84)  # Resize frames to 84x84\n",
    "env = dtype_v0(env, dtype=\"float32\")  # Convert observations to float32\n",
    "env = normalize_obs_v0(env, env_min=0, env_max=1)  # Normalize pixel values\n",
    "\n",
    "parallel_env = aec_to_parallel(env)  # Convert to parallel format\n",
    "\n",
    "# Step 2: Initialize PPO and RolloutBuffer\n",
    "obs_shape = (1, 84, 84)  # Single frame (no stacking)\n",
    "action_space = env.action_space(\"first_0\")  # Example action space for an agent\n",
    "ppo = PPO(obs_shape, action_space)\n",
    "\n",
    "# Load pre-trained models if necessary\n",
    "# ppo.load_value_network(value_model_path)  # load value network\n",
    "# ppo.load_policy_network(policy_model_path) # load policy network\n",
    "\n",
    "# Initialize the buffer\n",
    "buffer = RolloutBuffer()\n",
    "\n",
    "# Step 3: Training Loop\n",
    "num_episodes = 50\n",
    "max_steps_per_episode = 5000  # Maximum steps to prevent infinite loops\n",
    "self_play_checkpoint_interval = 2  # Save the policy every N episodes for self-play\n",
    "# Initialize reward tracking\n",
    "cumulative_rewards = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    # Reset the environment\n",
    "    observations = parallel_env.reset()\n",
    "\n",
    "    # Extract nested observations (first element of the tuple)\n",
    "    if isinstance(observations, tuple) and len(observations) > 0:\n",
    "        agent_observations = observations[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "    # Initialize done flags for each agent\n",
    "    done = {agent: False for agent in agent_observations.keys()}\n",
    "    step = 0\n",
    "    episode_reward = defaultdict(int)  # Track total reward for the episode\n",
    "\n",
    "    # Choose an opponent policy for this episode\n",
    "    if opponent_policies and random.random() < 0.5:\n",
    "        opponent_policy = random.choice(opponent_policies)\n",
    "    else:\n",
    "        opponent_policy = None  # Use random actions if no opponent policy exists\n",
    "\n",
    "    while not all(done.values()) and step < max_steps_per_episode:\n",
    "        actions = {}\n",
    "        log_probs = {}\n",
    "\n",
    "        # Process observations for each agent\n",
    "        for agent, obs in agent_observations.items():\n",
    "            # Convert observations to grayscale if needed\n",
    "            if obs.shape[-1] == 3:  # If RGB format\n",
    "                obs = obs.mean(axis=-1)  # Convert to grayscale by averaging RGB channels\n",
    "\n",
    "            # Prepare tensor\n",
    "            obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "\n",
    "            # Decide the policy for each agent\n",
    "            if agent == \"first_0\":\n",
    "                # Use the current PPO policy for the first agent\n",
    "                action_probs = ppo.policy.forward_policy(obs_tensor)\n",
    "            else:\n",
    "                # Use the opponent policy or random actions for the second agent\n",
    "                if opponent_policy:\n",
    "                    with torch.no_grad():\n",
    "                        action_probs = opponent_policy(obs_tensor)\n",
    "                else:\n",
    "                    action_probs = torch.ones(action_space.n) / action_space.n  # Uniform random actions\n",
    "\n",
    "            action = torch.multinomial(action_probs, 1).item()  # Sample action\n",
    "            log_probs[agent] = torch.log(action_probs.squeeze(0)[action])  # Log probability\n",
    "            actions[agent] = action  # Store action\n",
    "\n",
    "        # Step the environment\n",
    "        step_output = parallel_env.step(actions)\n",
    "\n",
    "        if len(step_output) == 5:  # Handle truncations\n",
    "            next_observations, rewards, dones, truncations, infos = step_output\n",
    "            dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "        else:\n",
    "            next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "        # Extract nested observations for next step\n",
    "        if isinstance(next_observations, dict):\n",
    "            agent_observations = next_observations  # Observations are already in dictionary format\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected observation structure after step: {type(next_observations)}\")\n",
    "\n",
    "        for agent, reward in rewards.items():\n",
    "            episode_reward[agent] += reward\n",
    "        \n",
    "        # Store data in the buffer for each agent\n",
    "        for agent, obs in agent_observations.items():\n",
    "            buffer.store(obs, actions[agent], log_probs[agent].item(), rewards[agent], dones[agent])\n",
    "\n",
    "        # Update done flags\n",
    "        done = dones\n",
    "        step += 1\n",
    "\n",
    "    # Append episode reward\n",
    "    cumulative_rewards.append(episode_reward)\n",
    "\n",
    "    # Compute Returns and Advantages\n",
    "    print(f\"Episode {episode + 1}: Episode Reward = {episode_reward}\")\n",
    "    buffer.compute_returns_and_advantages(ppo.policy, ppo.gamma, ppo.gae_lambda)\n",
    "\n",
    "    # Update PPO\n",
    "    print(f\"Episode {episode + 1}: Updating PPO model...\")\n",
    "    policy_losses, value_losses, total_losses = ppo.update(buffer)\n",
    "\n",
    "    # Save the current policy for self-play periodically\n",
    "    if (episode + 1) % self_play_checkpoint_interval == 0:\n",
    "        saved_policy = PPOAgent(obs_shape, action_space)\n",
    "        saved_policy.load_state_dict(ppo.policy.state_dict())\n",
    "        opponent_policies.append(saved_policy)\n",
    "        print(f\"Checkpoint: Saved policy for self-play after Episode {episode + 1}\")\n",
    "\n",
    "    # Clear buffer for the next episode\n",
    "    buffer.clear()\n",
    "\n",
    "    # Log progress\n",
    "    print(f\"Episode {episode + 1}/{num_episodes} completed.\")\n",
    "\n",
    "# Plot cumulative rewards\n",
    "plt.plot([sum(reward.values()) for reward in cumulative_rewards])\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Training Progress with Self-Play')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m agent_rewards \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode_rewards \u001b[38;5;129;01min\u001b[39;00m cumulative_rewards:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent, reward \u001b[38;5;129;01min\u001b[39;00m \u001b[43mepisode_rewards\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m agent \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m agent_rewards:\n\u001b[1;32m      6\u001b[0m             agent_rewards[agent] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Extract rewards for each agent\n",
    "agent_rewards = {}\n",
    "for episode_rewards in cumulative_rewards:\n",
    "    for agent, reward in episode_rewards.items():\n",
    "        if agent not in agent_rewards:\n",
    "            agent_rewards[agent] = []\n",
    "        agent_rewards[agent].append(reward)\n",
    "\n",
    "# Plot cumulative rewards for each agent\n",
    "plt.figure(figsize=(12, 6))\n",
    "for agent, rewards in agent_rewards.items():\n",
    "    cumulative_sum = np.cumsum(rewards)\n",
    "    plt.plot(cumulative_sum, label=f\"Agent: {agent}\")\n",
    "\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Reward')\n",
    "plt.title('Training Progress: Cumulative Rewards Per Agent')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.plot(policy_losses, label='Policy Loss')\n",
    "# plt.plot(value_losses, label='Value Loss')\n",
    "plt.plot(total_losses, label='Total Loss')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained PPO models saved:\n",
      "Policy model: ppo_trained_models_Dec_11/ppo_policy_model.pth\n",
      "Value model: ppo_trained_models_Dec_11/ppo_value_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the trained PPO models\n",
    "torch.save(ppo.policy.state_dict(), policy_model_path)\n",
    "torch.save(ppo.policy.value_net.state_dict(), value_model_path)\n",
    "\n",
    "print(f\"Trained PPO models saved:\")\n",
    "print(f\"Policy model: {policy_model_path}\")\n",
    "print(f\"Value model: {value_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for agent, reward in rewards.items():\n",
    "#         if reward != 0:\n",
    "#             print(f\"step: {step}, Agent: {agent}, Reward: {reward}\")\n",
    "#         cumulative_rewards[agent] += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Actions: {'first_0': 12, 'second_0': 10}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "print(f\"Sampled Actions: {actions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: first_0, Sampled Action: 4\n",
      "Agent: second_0, Sampled Action: 8\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    action = env.action_space(agent).sample()\n",
    "    print(f\"Agent: {agent}, Sampled Action: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_accumulate_rewards', '_check_wrapper_params', '_clear_rewards', '_deads_step_first', '_has_rendered', '_has_reset', '_has_updated', '_is_protocol', '_modify_action', '_modify_observation', '_modify_spaces', '_update_step', '_was_dead_step', 'action_space', 'agent_iter', 'change_obs_space_fn', 'change_observation_fn', 'close', 'env', 'last', 'max_num_agents', 'num_agents', 'observation_space', 'observe', 'render', 'reset', 'state', 'step', 'unwrapped']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dir(env))  # Check available attributes and methods\n",
    "print(env.reset.__doc__)  # Print the docstring of the reset method if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2200, Agent: first_0, Reward: 1\n",
      "step: 2200, Agent: second_0, Reward: -1\n",
      "step: 2911, Agent: first_0, Reward: -1\n",
      "step: 2911, Agent: second_0, Reward: 1\n",
      "step: 5980, Agent: first_0, Reward: -1\n",
      "step: 5980, Agent: second_0, Reward: 1\n",
      "step: 6047, Agent: first_0, Reward: 1\n",
      "step: 6047, Agent: second_0, Reward: -1\n",
      "step: 6394, Agent: first_0, Reward: -1\n",
      "step: 6394, Agent: second_0, Reward: 1\n",
      "step: 7080, Agent: first_0, Reward: 1\n",
      "step: 7080, Agent: second_0, Reward: -1\n",
      "Cumulative Rewards: defaultdict(<class 'int'>, {'first_0': 0, 'second_0': 0})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reset the environment\n",
    "observations = parallel_env.reset()\n",
    "\n",
    "# Initialize a variable to store observations\n",
    "step_1_observation = None\n",
    "step_100_observation = None\n",
    "cumulative_rewards = defaultdict(int)\n",
    "\n",
    "for step in range(8000):\n",
    "    # Sample random actions for all agents\n",
    "    actions = {agent: parallel_env.action_space(agent).sample() for agent in parallel_env.agents}\n",
    "\n",
    "    # Step the environment\n",
    "    step_output = parallel_env.step(actions)\n",
    "\n",
    "    if len(step_output) == 5:  # Handle truncations\n",
    "        next_observations, rewards, dones, truncations, infos = step_output\n",
    "        dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "    else:\n",
    "        next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "    \n",
    "    # Store the first and 100th observations\n",
    "    if step == 0:\n",
    "        step_1_observation = next_observations.copy()\n",
    "    if step == 5999:\n",
    "        step_100_observation = next_observations.copy()\n",
    "\n",
    "    for agent, reward in rewards.items():\n",
    "        if reward != 0:\n",
    "            print(f\"step: {step}, Agent: {agent}, Reward: {reward}\")\n",
    "        cumulative_rewards[agent] += reward\n",
    "    \n",
    "    # Break if the environment is done\n",
    "    if all(dones.values()):\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Cumulative Rewards: {cumulative_rewards}\")\n",
    "\n",
    "# Visualize the observations for the first and 100th steps\n",
    "agent = list(next_observations.keys())[0]  # Pick the first agent for visualization\n",
    "\n",
    "# Convert the observations to grayscale if they are in RGB format\n",
    "def preprocess_observation(obs):\n",
    "    if len(obs.shape) == 3 and obs.shape[-1] == 3:  # RGB format\n",
    "        obs = np.mean(obs, axis=-1)  # Convert to grayscale\n",
    "    return obs\n",
    "\n",
    "step_1_frame = preprocess_observation(step_1_observation[agent])\n",
    "step_100_frame = preprocess_observation(step_100_observation[agent])\n",
    "\n",
    "# Plot the frames\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Step 1 observation\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(step_1_frame, cmap='gray')\n",
    "plt.title(\"Step 1 Observation\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Step 100 observation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(step_100_frame, cmap='gray')\n",
    "plt.title(\"Step 100 Observation\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict() -> new empty dictionary\n",
      "dict(mapping) -> new dictionary initialized from a mapping object's\n",
      "    (key, value) pairs\n",
      "dict(iterable) -> new dictionary initialized as if via:\n",
      "    d = {}\n",
      "    for k, v in iterable:\n",
      "        d[k] = v\n",
      "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      "    in the keyword argument list.  For example:  dict(one=1, two=2)\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for agent, obs in next_observations.items():\n",
    "#     plt.imshow(obs)  # Assuming observations are raw frames\n",
    "#     plt.title(f\"Agent: {agent}\")\n",
    "#     plt.show()\n",
    "\n",
    "print(env.rewards.__doc__)  # Print the docstring of the rewards method if available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Set up the environment\n",
    "# env = boxing_v2.env(render_mode=\"rgb_array\")\n",
    "# env.reset(seed=42)\n",
    "# env = frame_skip_v0(env, 4)  # Frame skipping\n",
    "# env = pad_observations_v0(env)\n",
    "# env = pad_action_space_v0(env)\n",
    "# env = resize_v1(env, 84, 84)  # Resize frames to 84x84\n",
    "# env = dtype_v0(env, dtype=\"float32\")  # Convert observations to float32\n",
    "# env = normalize_obs_v0(env, env_min=0, env_max=1)  # Normalize pixel values\n",
    "\n",
    "# parallel_env = aec_to_parallel(env)  # Convert to parallel format\n",
    "\n",
    "# # Step 2: Initialize PPO and RolloutBuffer\n",
    "# obs_shape = (1, 84, 84)  # Single frame (no stacking)\n",
    "# action_space = env.action_space(\"first_0\")  # Example action space for an agent\n",
    "# ppo = PPO(obs_shape, action_space)\n",
    "# buffer = RolloutBuffer()\n",
    "\n",
    "# # Step 3: Training Loop\n",
    "# num_episodes = 5\n",
    "# max_steps_per_episode = 3000  # Maximum steps to prevent infinite loops\n",
    "# # Initialize reward tracking\n",
    "# cumulative_rewards = []\n",
    "\n",
    "# for episode in range(num_episodes):\n",
    "#     # Reset the environment\n",
    "#     observations = parallel_env.reset()\n",
    "\n",
    "#     # Extract nested observations (first element of the tuple)\n",
    "#     if isinstance(observations, tuple) and len(observations) > 0:\n",
    "#         agent_observations = observations[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "#     # Initialize done flags for each agent\n",
    "#     done = {agent: False for agent in parallel_env.agents} # updated for skipping***********************************************\n",
    "#     step = 0\n",
    "#     episode_reward = defaultdict(int)  # Track total reward for the episode\n",
    "\n",
    "#     while not all(done.values()) and step < max_steps_per_episode:\n",
    "#         actions = {}\n",
    "#         log_probs = {}\n",
    "\n",
    "#         # Process observations for each agent\n",
    "#         for agent in parallel_env.agents:\n",
    "#             # print(f\"Agent: {agent}\")\n",
    "#             if done[agent]:\n",
    "#                 # Provide a placeholder action for done agents\n",
    "#                 actions[agent] = parallel_env.action_space(agent).sample()\n",
    "#             else:\n",
    "#                 obs = agent_observations[agent]\n",
    "#                 if obs.shape[-1] == 3:  # If RGB format\n",
    "#                     obs = obs.mean(axis=-1)  # Convert to grayscale by averaging RGB channels\n",
    "#                 obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "#                 action_probs = ppo.policy.forward_policy(obs_tensor)\n",
    "#                 action = torch.multinomial(action_probs, 1).item()\n",
    "#                 actions[agent] = action\n",
    "\n",
    "\n",
    "#         # Step the environment\n",
    "#         try:\n",
    "#             step_output = parallel_env.step(actions)\n",
    "#         except AssertionError as e:\n",
    "#             # Handle any unexpected sequence errors\n",
    "#             print(f\"Assertion Error: {e}\")\n",
    "#             break\n",
    "\n",
    "#         # Handle the step output\n",
    "#         if len(step_output) == 5:  # Handle truncations\n",
    "#             next_observations, rewards, dones, truncations, infos = step_output\n",
    "#             dones = {agent: dones.get(agent, False) or truncations.get(agent, False) for agent in parallel_env.agents}\n",
    "#         else:\n",
    "#             next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "#         # Update done flags\n",
    "#         done = {agent: dones.get(agent, False) for agent in parallel_env.agents}\n",
    "\n",
    "#         # Ensure `agent_observations` and other dictionaries are in sync\n",
    "#         if isinstance(next_observations, dict):\n",
    "#             agent_observations = {agent: next_observations.get(agent, None) for agent in parallel_env.agents}\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unexpected observation structure after step: {type(next_observations)}\")\n",
    "\n",
    "#         # Update rewards and store observations in the buffer\n",
    "#         for agent in parallel_env.agents:\n",
    "#             if not done.get(agent, False):\n",
    "#                 obs = agent_observations.get(agent)\n",
    "#                 if obs is None:\n",
    "#                     print(f\"Warning: Missing observation for agent {agent} at step {step}. Skipping.\")\n",
    "#                     continue\n",
    "#                 buffer.store(\n",
    "#                     obs,\n",
    "#                     actions.get(agent, parallel_env.action_space(agent).sample()),\n",
    "#                     log_probs.get(agent, 0.0),\n",
    "#                     rewards.get(agent, 0.0),\n",
    "#                     done.get(agent, False)\n",
    "#                 )\n",
    "#                 episode_reward[agent] += rewards.get(agent, 0.0)\n",
    "\n",
    "#         # Ensure buffer is not empty\n",
    "#         if len(buffer.observations) == 0:\n",
    "#             print(f\"Warning: Buffer is empty after step {step}.\")\n",
    "\n",
    "#         # Update done flags\n",
    "#         done = {agent: dones[agent] or truncations[agent] for agent in parallel_env.agents}\n",
    "#         step += 1\n",
    "\n",
    "#     # Append episode reward\n",
    "#     cumulative_rewards.append(episode_reward)\n",
    "\n",
    "#     # Compute Returns and Advantages\n",
    "#     print(f\"Episode {episode + 1}: Episode Reward = {episode_reward}\")\n",
    "#     buffer.compute_returns_and_advantages(ppo.policy, ppo.gamma, ppo.gae_lambda)\n",
    "\n",
    "#     # Update PPO\n",
    "#     print(f\"Episode {episode + 1}: Updating PPO model...\")\n",
    "#     ppo.update(buffer)\n",
    "\n",
    "#     # Clear buffer for the next episode\n",
    "#     buffer.clear()\n",
    "\n",
    "#     # Log progress\n",
    "#     print(f\"Episode {episode + 1}/{num_episodes} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for episode in range(num_episodes):\n",
    "#     # Reset the environment\n",
    "#     observations = parallel_env.reset()\n",
    "\n",
    "#     # Extract nested observations (first element of the tuple)\n",
    "#     if isinstance(observations, tuple) and len(observations) > 0:\n",
    "#         agent_observations = observations[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unexpected observation structure: {type(observations)}\")\n",
    "\n",
    "#     # Initialize done flags for each agent\n",
    "#     done = {agent: False for agent in agent_observations.keys()}\n",
    "#     step = 0\n",
    "\n",
    "#     while not all(done.values()) and step < max_steps_per_episode:\n",
    "#         actions = {}\n",
    "#         log_probs = {}\n",
    "\n",
    "#         # Process observations for each agent\n",
    "#         for agent, obs in agent_observations.items():\n",
    "#             # Convert observations to grayscale if needed\n",
    "#             if obs.shape[-1] == 3:  # If RGB format\n",
    "#                 obs = obs.mean(axis=-1)  # Convert to grayscale by averaging RGB channels\n",
    "\n",
    "#             # Prepare tensor with correct dimensions\n",
    "#             obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "\n",
    "#             # Get action probabilities\n",
    "#             action_probs = ppo.policy.forward_policy(obs_tensor)\n",
    "#             action = torch.multinomial(action_probs, 1).item()  # Sample action\n",
    "#             log_probs[agent] = torch.log(action_probs.squeeze(0)[action])  # Log probability\n",
    "#             actions[agent] = action  # Store action\n",
    "\n",
    "#         # Step the environment\n",
    "#         step_output = parallel_env.step(actions)\n",
    "\n",
    "#         if len(step_output) == 5:  # Handle truncations\n",
    "#             next_observations, rewards, dones, truncations, infos = step_output\n",
    "#             dones = {agent: dones[agent] or truncations[agent] for agent in dones}\n",
    "#         else:\n",
    "#             next_observations, rewards, dones, infos = step_output\n",
    "\n",
    "#         # Extract nested observations for next step\n",
    "#         if isinstance(next_observations, dict):\n",
    "#             agent_observations = next_observations  # Observations are already in dictionary format\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unexpected observation structure after step: {type(next_observations)}\")\n",
    "\n",
    "\n",
    "#         # Store data in the buffer for each agent\n",
    "#         for agent, obs in agent_observations.items():\n",
    "#             buffer.store(obs, actions[agent], log_probs[agent].item(), rewards[agent], dones[agent])\n",
    "\n",
    "#         # Update done flags\n",
    "#         done = dones\n",
    "#         step += 1\n",
    "\n",
    "#     # Compute Returns and Advantages\n",
    "#     print(f\"Episode {episode + 1}: Computing returns and advantages...\")\n",
    "#     buffer.compute_returns_and_advantages(ppo.policy, ppo.gamma, ppo.gae_lambda)\n",
    "\n",
    "#     # Update PPO\n",
    "#     print(f\"Episode {episode + 1}: Updating PPO model...\")\n",
    "#     ppo.update(buffer)\n",
    "\n",
    "#     # Clear buffer for the next episode\n",
    "#     buffer.clear()\n",
    "\n",
    "#     # Log progress\n",
    "#     print(f\"Episode {episode + 1}/{num_episodes} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS153",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
